{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"cs-training.csv\")\n",
    "df_test = pd.read_csv(\"cs-test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.dropna(subset=['NumberOfDependents'], inplace=True)   # 가구원 수에 결측치가 있는 샘플 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146076, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 새로운 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = df_train.append(df_test)   # 전처리 같이 해주기 위해서 붙여주고 나중에 분리해줄 예정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins= [20,60,80,120]\n",
    "labels_age = ['Adult','Young Senior','Senior']\n",
    "df_append['AgeGroup'] = pd.cut(df_append['age'], bins=bins, labels=labels_age, right=False)   # 구간별로 구분해주고 이름도 붙여줌.\n",
    "mask_2 = {\n",
    "         'Adult':0,\n",
    "         'Young Senior':1,\n",
    "         'Senior':2}\n",
    "df_append['AgeGroup'].replace(mask_2,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.cut method는 특정 구간 별로 구분해 카테고리화를 하고 싶을 때 사용한다. 20살에서 60살은 'Adult'. 60살에서 80은 'Yong Senior'. 80에서 120은 'Senior'로 했다.   \n",
    "단순 boolean 조건절은 np.where로도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    168451\n",
       "1.0     69838\n",
       "2.0      9289\n",
       "Name: AgeGroup, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_append['AgeGroup'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결측치 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append['MonthlyIncome'].fillna(df_append['MonthlyIncome'].median(),inplace=True)\n",
    "df_append['NumberOfDependents'].fillna(df_append['NumberOfDependents'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_append[0:146076]\n",
    "df_test = df_append[146076:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='AgeGroup', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"AgeGroup\", data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['AgeGroup'].fillna(df_train['AgeGroup'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기까지 전처리 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,roc_curve\n",
    "def plot_roc(pred):\n",
    "    fpr,tpr,_ = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    sns.lineplot(fpr, tpr, label = 'AUC = %0.4f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__이해가 안 되는 걸 가져오기 싫었지만 앞으로 유용할 것 같아서 가져옴.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 머신러닝 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridCV를 활용한 최적의 파라메터를 탐색하기 위해 Train 데이터 내에서 Train 데이터와 Test 데이터로 나눠준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_train.drop(['Unnamed: 0','SeriousDlqin2yrs'],axis=1)\n",
    "SeriousDlqIn2Yrs = df_train['SeriousDlqin2yrs']\n",
    "test_df = df_test.drop(['Unnamed: 0','SeriousDlqin2yrs'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_df = SeriousDlqIn2Yrs\n",
    "X_df = train_df\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_df,y_df,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 첫번째 분류모델. 의사결정나무\n",
    "##### 데이터 균일도를 바탕으로 규칙기반으로 분류해나가는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "dt_clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최고 평균 roc_auc 점수: 0.8452448635741601\n",
      "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 7, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "params2={'max_depth':[1,2,3,5,7,10],\n",
    "       'min_samples_split':[5,10,20]}\n",
    "grid_cv2=GridSearchCV(dt_clf,param_grid=params2,scoring='roc_auc',cv=5)\n",
    "grid_cv2.fit(X_train,y_train)\n",
    "print('GridSearchCV 최고 평균 roc_auc 점수:',grid_cv2.best_score_)\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:',grid_cv2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정트리 예측 roc_auc: 0.739467845909129\n"
     ]
    }
   ],
   "source": [
    "best_df_clf=grid_cv2.best_estimator_\n",
    "pred_df=best_df_clf.predict(X_test)\n",
    "roc_auc=roc_auc_score(pred_df,y_test)\n",
    "print('결정트리 예측 roc_auc:',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs=pd.DataFrame(best_df_clf.predict_proba(test_df))[1]\n",
    "pred_probs.index += 1 \n",
    "pred_probs.to_csv(r\"submit_dctree_data2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 두번째 분류모델. 랜덤포레스트\n",
    "##### 랜덤포레스트는 배깅의 한종류로, 같은 알고리즘(의사결정나무)로 여러 개의 분류기를 만들어서 투표를 통해 최종 결정하는 알고리즘. 분류기들에 가중치를 주어 선형결합을 통해 최종 결과를 예측하는 방법에 해당. 쉽게 말해, 기본적인 의사결정나무와는 달리 부트스트랩 방식을 통해 전체데이터에서 중복을 허용하여 n개의 데이터를 추출하고, 또한 피처값 중에서 중복 허용 없이 k개를 추출하여 만든 데이터를 바탕으로 분류기에 넣어 데이터를 예측한다. 이러한 과정을 여러 번 반복하여 여러 개의 분류기에서 나온 결과값을 바탕으로 예측을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터와 예측 roc_auc 점수: {'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 3} 0.8621199369865301\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "    'max_depth':[1,3,5,10],\n",
    "    'min_samples_leaf':[1,3,5,10],\n",
    "    'min_samples_split':[1,3,5,10]\n",
    "    }\n",
    "#RandomForest를 설정하고 GridSearchCV수행\n",
    "rf_clf=RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid=params,cv=3,n_jobs=-1,scoring='roc_auc')\n",
    "grid_cv.fit(X_train,y_train)\n",
    "cv_result=pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "print('최적 하이퍼 파라미터와 예측 roc_auc 점수:',grid_cv.best_params_,grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤포레스트 예측 roc_auc: 0.7741243224771318\n"
     ]
    }
   ],
   "source": [
    "rf_clf=RandomForestClassifier(max_depth=10, min_samples_leaf=10, min_samples_split=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf_pred = rf_clf.predict(X_test)\n",
    "roc_auc = roc_auc_score(rf_clf_pred,y_test)\n",
    "print('랜덤포레스트 예측 roc_auc:',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제출 데이터 생성\n",
    "rf_clf=RandomForestClassifier(max_depth=10, min_samples_leaf=10, min_samples_split=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred_probs=pd.DataFrame(rf_clf.predict_proba(test_df))[1]\n",
    "rf_wrapper_pred=pd.DataFrame(pred_probs)\n",
    "rf_wrapper_pred.index += 1 \n",
    "rf_wrapper_pred.to_csv(r\"submit_rf_data2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf=RandomForestClassifier(max_depth=13, min_samples_leaf=10, min_samples_split=3)\n",
    "rf_clf.fit(X_df, y_df)\n",
    "pred_probs=pd.DataFrame(rf_clf.predict_proba(test_df))[1]\n",
    "rf_wrapper_pred=pd.DataFrame(pred_probs)\n",
    "rf_wrapper_pred.index += 1 \n",
    "rf_wrapper_pred.to_csv(r\"submit_rf_data2-15.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 세번째 분류모델. XG부스트(회귀도 가능)\n",
    "##### 부스팅 알고리즘은 분포에 대해 약한 학습자를 반복적으로 학습시켜 최종적으로 강한 학습자를 만드는 것을 목표로한다. 강한 학습자를 만들기 위해 약한 학습자들의 잔차가 큰 잘못 예측한 데이터에 대해 가중치를 부여하여 예측성을 향상시키고자 한다. 의사결정나무를 기반으로 분석하는 부스팅 기법에는 LightGBM과 XGboost가 있으며, 타 부스팅 기법 대시 분석 소요 시간을 획기적으로 줄이면서도, 예측력은 그대로 유지하고 있거나 더 뛰어나다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터와 예측 roc_auc 점수: {'learning_rate': 1, 'max_depth': 3, 'n_estimators': 10, 'random_state': 1} 0.8571084907620922\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "y_org = y_train\n",
    "X_org = X_train\n",
    "\n",
    "params={\n",
    "    'max_depth':[1,3,5,10],\n",
    "    'learning_rate':[1,3,5,10],\n",
    "    'n_estimators':[1,3,5,10],\n",
    "    'random_state':[1,3,5,10]\n",
    "    }\n",
    "\n",
    "xgb_wrapper = XGBClassifier()\n",
    "grid_cv = GridSearchCV(xgb_wrapper, param_grid=params,cv=5,n_jobs=-1,scoring='roc_auc')\n",
    "grid_cv.fit(X_train,y_train)\n",
    "\n",
    "cv_result=pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "print('최적 하이퍼 파라미터와 예측 roc_auc 점수:',grid_cv.best_params_,grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.24824\n",
      "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-logloss:0.19544\n",
      "[2]\tvalidation_0-logloss:0.18358\n",
      "[3]\tvalidation_0-logloss:0.18131\n",
      "[4]\tvalidation_0-logloss:0.17997\n",
      "[5]\tvalidation_0-logloss:0.17956\n",
      "[6]\tvalidation_0-logloss:0.17947\n",
      "[7]\tvalidation_0-logloss:0.17944\n",
      "[8]\tvalidation_0-logloss:0.17915\n",
      "[9]\tvalidation_0-logloss:0.17915\n",
      "XGBoost 예측 roc_auc: 0.739467845909129\n"
     ]
    }
   ],
   "source": [
    "y_org = y_train\n",
    "X_org = X_train\n",
    "\n",
    "xgb_wrapper = XGBClassifier(learning_rate=1 , max_depth=3, n_estimators=10, random_state=1)\n",
    "evals=[(X_test,y_test)]\n",
    "xgb_wrapper.fit(X_org, y_org, early_stopping_rounds=100, eval_metric=\"logloss\",eval_set=evals,verbose=True)\n",
    "xgb_wrapper_pred = xgb_wrapper.predict(X_test)\n",
    "print('XGBoost 예측 roc_auc:',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#제출 데이터 생성\n",
    "pred_probs=pd.DataFrame(xgb_wrapper.predict_proba(test_df))[1]\n",
    "xgb_wrapper_pred=pd.DataFrame(pred_probs)\n",
    "xgb_wrapper_pred.index += 1 \n",
    "xgb_wrapper_pred\n",
    "xgb_wrapper_pred.to_csv(r\"submit_xgboost_data2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네번쨰 분류모델. LightGBM\n",
    "##### XG부스트의 개선 분류모델. XG부스트는 부스팅 모델중에서 상대적으로 빠르긴하나, 여전히 시간이 오래 걸린다는 문제점을 가지고 있습니다. 예측성을 유지하면서도 이러한 문제를 해결한 알고리즘이 LightGBM이다. LightGBM은 대용량 데이터 처리에 적합하며, 메모리 사용량도 적으며, CPU뿐만 아니라 GPU도 활용가능하다. 다만, 너무 적은 양의 데이터에 사용시 과적합 문제가 발생할 가능성이 높다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'max_depth':[1,3,5,10],\n",
    "    'learning_rate':[0.5,1,3,5,10],\n",
    "    'n_estimators':[1,3,5,10],\n",
    "    'random_state':[1,3,5,10]\n",
    "    }\n",
    "\n",
    "LGBM_wrapper = LGBMClassifier()\n",
    "grid_cv = GridSearchCV(LGBM_wrapper, param_grid=params,cv=5,n_jobs=-1,scoring='roc_auc')\n",
    "grid_cv.fit(X_train,y_train)\n",
    "\n",
    "cv_result=pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "print('최적 하이퍼 파라미터와 예측 roc_auc 점수:',grid_cv.best_params_,grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.200247\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.191184\n",
      "[3]\tvalid_0's binary_logloss: 0.185821\n",
      "[4]\tvalid_0's binary_logloss: 0.183254\n",
      "[5]\tvalid_0's binary_logloss: 0.181818\n",
      "[6]\tvalid_0's binary_logloss: 0.180903\n",
      "[7]\tvalid_0's binary_logloss: 0.180281\n",
      "[8]\tvalid_0's binary_logloss: 0.179871\n",
      "[9]\tvalid_0's binary_logloss: 0.179186\n",
      "[10]\tvalid_0's binary_logloss: 0.178759\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's binary_logloss: 0.178759\n",
      "LightGBM 최적 파라미터 roc_auc 예측 점수: 0.7510864646723432\n"
     ]
    }
   ],
   "source": [
    "lgbm_wrapper_time=LGBMClassifier(learning_rate=0.5, max_depth=3, n_estimators=10, random_state=1)\n",
    "evals=[(X_test,y_test)]\n",
    "lgbm_wrapper_time.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\",eval_set=evals,verbose=True)\n",
    "lgbm_wrapper_time_preds=lgbm_wrapper_time.predict(X_test)\n",
    "lgbm_time_roc_auc = roc_auc_score(lgbm_wrapper_time_preds,y_test )\n",
    "print('LightGBM 최적 파라미터 roc_auc 예측 점수:',lgbm_time_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs=pd.DataFrame(lgbm_wrapper_time.predict_proba(test_df))[1]\n",
    "lgbm_wrapper_pred=pd.DataFrame(pred_probs)\n",
    "lgbm_wrapper_pred.index += 1 \n",
    "lgbm_wrapper_pred\n",
    "lgbm_wrapper_pred.to_csv(r\"submit_lgbm_data2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
