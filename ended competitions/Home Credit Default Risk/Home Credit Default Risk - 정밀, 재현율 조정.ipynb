{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder # 범주형 변수처리\n",
    "\n",
    "# File system manangement\n",
    "import os # 파일 시스템 관리\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "app_train = pd.read_csv(\"application_train.csv\")\n",
    "print('Training data shape: ', app_train.shape) # 크기 확인\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (48744, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "app_test = pd.read_csv(\"application_test.csv\")\n",
    "print('Training data shape: ', app_test.shape) # 크기 확인\n",
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 121)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가변수는 해당 범주에 해당하는 경우 1, 아닌 경우 0으로 값을 입력해서 범주형 자료의 값을 인식할 수 있도록 해준다.\n",
    "범주형 자료를 가변수로 변환해주는 operator는 get_dummies()가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object': # 칼럼이 object타입이면\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col]) # 라벨인코딩\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 243)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "# align : 동시에 존재하는 칼럼을 출력해여 동일한 순서로 배열\n",
    "# join = 'inner' : (교집합 외)동시에 존재하지 않는 칼럼은 삭제\n",
    "\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07823930830984513"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
    "app_train['DAYS_BIRTH'].corr(app_train['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 해당 명령어   \n",
    "app_test['DAYS_EMPLOYED'] = abs(app_test['DAYS_EMPLOYED'])  \n",
    "app_test['DAYS_LAST_PHONE_CHANGE'] = abs(app_test['DAYS_LAST_PHONE_CHANGE'])  \n",
    "가 없는 이유는?\n",
    "A. 위에선 새로 만든 변수들을 이용해 분석을 할 예정이었지만 지금은 다항 변수를 만들어 분석을 할 것이기에 필요가 없기 때문이다. 단, 'DAYS_BIRTH'는 상관계수가 높아 사용될 예정이므로 abs operator를 사용했다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test['DAYS_BIRTH'] = abs(app_test['DAYS_BIRTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg1_train_t = app_train['TARGET']\n",
    "kg1_train_f = app_train.drop(['TARGET'], axis=1)\n",
    "kg1_test_f = app_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치를 처리하지 않은 데이터를 kg1_train_t, kg1_train_f, kg1_test_f로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe for polynomial features(다항 변수를 만들어 보자)\n",
    "poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
    "poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "\n",
    "# imputer for handling missing values\n",
    "from sklearn.impute import SimpleImputer   # SimpleImputer는 결측치를 간편하게 처리해주는 클래스.\n",
    "imputer = SimpleImputer(strategy = 'median')   # 결측치 중앙값으로 입력\n",
    "\n",
    "poly_target = poly_features['TARGET']\n",
    "poly_features = poly_features.drop(columns = ['TARGET'])\n",
    "\n",
    "# Need to impute missing values\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "poly_features_test = imputer.transform(poly_features_test)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures   # PolynomialFeatures 다항차수 변환을 해주는 클래스.\n",
    "                                  \n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree = 3)   # 3차 다항식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT_SOURCE_3                           -0.178919\n",
      "EXT_SOURCE_2                           -0.160472\n",
      "EXT_SOURCE_1                           -0.155317\n",
      "DAYS_BIRTH                             -0.078239\n",
      "NAME_EDUCATION_TYPE_Higher education   -0.056593\n",
      "                                          ...   \n",
      "NAME_INCOME_TYPE_Working                0.057481\n",
      "REGION_RATING_CLIENT                    0.058899\n",
      "REGION_RATING_CLIENT_W_CITY             0.060893\n",
      "DAYS_EMPLOYED                           0.074958\n",
      "TARGET                                  1.000000\n",
      "Name: TARGET, Length: 241, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 왜 위의 식에서 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'의 변수를 선택했을까?\n",
    "# 상관행렬을 봤을 때 Target에 미치는 영향이 가장 커보였기 때문.\n",
    "corr = app_train.corr()['TARGET'].sort_values()\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features shape:  (307511, 35)\n",
      "Polynomial Features test shape:  (48744, 35)\n"
     ]
    }
   ],
   "source": [
    "# Train the polynomial features\n",
    "poly_transformer.fit(poly_features)   # poly_features의 변수를 3차 다항식으로 변환하는 것이다.\n",
    "\n",
    "# Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "print('Polynomial Features shape: ', poly_features.shape)\n",
    "print('Polynomial Features test shape: ', poly_features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다항 변환을 했을 경우의 예: $x_1, x_2 -> 1, x_1, x_2, x_1^2, x_2^2, x_1x_2, x_1^3, x_2^3, x_1^2x_2^1, x_1x_2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'EXT_SOURCE_1',\n",
       " 'EXT_SOURCE_2',\n",
       " 'EXT_SOURCE_3',\n",
       " 'DAYS_BIRTH',\n",
       " 'EXT_SOURCE_1^2',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_2',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_1 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_2^2',\n",
       " 'EXT_SOURCE_2 EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_2 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_3^2',\n",
       " 'EXT_SOURCE_3 DAYS_BIRTH',\n",
       " 'DAYS_BIRTH^2',\n",
       " 'EXT_SOURCE_1^3',\n",
       " 'EXT_SOURCE_1^2 EXT_SOURCE_2',\n",
       " 'EXT_SOURCE_1^2 EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_1^2 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_2^2',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_2 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_3^2',\n",
       " 'EXT_SOURCE_1 EXT_SOURCE_3 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_1 DAYS_BIRTH^2',\n",
       " 'EXT_SOURCE_2^3',\n",
       " 'EXT_SOURCE_2^2 EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_2^2 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_2 EXT_SOURCE_3^2',\n",
       " 'EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_2 DAYS_BIRTH^2',\n",
       " 'EXT_SOURCE_3^3',\n",
       " 'EXT_SOURCE_3^2 DAYS_BIRTH',\n",
       " 'EXT_SOURCE_3 DAYS_BIRTH^2',\n",
       " 'DAYS_BIRTH^3']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])   # 변수이름 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT_SOURCE_2 EXT_SOURCE_3                -0.193939\n",
      "EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3   -0.189605\n",
      "EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH     -0.181283\n",
      "EXT_SOURCE_2^2 EXT_SOURCE_3              -0.176428\n",
      "EXT_SOURCE_2 EXT_SOURCE_3^2              -0.172282\n",
      "EXT_SOURCE_1 EXT_SOURCE_2                -0.166625\n",
      "EXT_SOURCE_1 EXT_SOURCE_3                -0.164065\n",
      "EXT_SOURCE_2                             -0.160295\n",
      "EXT_SOURCE_2 DAYS_BIRTH                  -0.156873\n",
      "EXT_SOURCE_1 EXT_SOURCE_2^2              -0.156867\n",
      "Name: TARGET, dtype: float64\n",
      "DAYS_BIRTH     -0.078239\n",
      "DAYS_BIRTH^2   -0.076672\n",
      "DAYS_BIRTH^3   -0.074273\n",
      "TARGET          1.000000\n",
      "1                    NaN\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of the features \n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                           'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Add in the target\n",
    "poly_features['TARGET'] = poly_target   # target을 왜 추가했을까? 밑에 코드 돌릴라고\n",
    "\n",
    "# Find the correlations with the target\n",
    "poly_corrs = poly_features.corr()['TARGET'].sort_values()  \n",
    "\n",
    "# Display most negative and most positive\n",
    "print(poly_corrs.head(10))\n",
    "print(poly_corrs.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상관행렬을 통해 TARGET 변수와 상관계수를 확인해보니 이전보다 높은 상관성을 가진 변수들이 생성이 됐음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 37)\n",
      "(48744, 36)\n",
      "Training data with polynomial features shape:  (307511, 275)\n",
      "Testing data with polynomial features shape:   (48744, 275)\n",
      "        SK_ID_CURR  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
      "0           100002                   0             0                1   \n",
      "1           100003                   0             0                0   \n",
      "2           100004                   1             1                1   \n",
      "3           100006                   0             0                1   \n",
      "4           100007                   0             0                1   \n",
      "...            ...                 ...           ...              ...   \n",
      "307506      456251                   0             0                0   \n",
      "307507      456252                   0             0                1   \n",
      "307508      456253                   0             0                1   \n",
      "307509      456254                   0             0                1   \n",
      "307510      456255                   0             0                0   \n",
      "\n",
      "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
      "0                  0          202500.0    406597.5      24700.5   \n",
      "1                  0          270000.0   1293502.5      35698.5   \n",
      "2                  0           67500.0    135000.0       6750.0   \n",
      "3                  0          135000.0    312682.5      29686.5   \n",
      "4                  0          121500.0    513000.0      21865.5   \n",
      "...              ...               ...         ...          ...   \n",
      "307506             0          157500.0    254700.0      27558.0   \n",
      "307507             0           72000.0    269550.0      12001.5   \n",
      "307508             0          153000.0    677664.0      29979.0   \n",
      "307509             0          171000.0    370107.0      20205.0   \n",
      "307510             0          157500.0    675000.0      49117.5   \n",
      "\n",
      "        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  ...  EXT_SOURCE_2^3  \\\n",
      "0              351000.0                    0.018801  ...        0.018181   \n",
      "1             1129500.0                    0.003541  ...        0.240927   \n",
      "2              135000.0                    0.010032  ...        0.171798   \n",
      "3              297000.0                    0.008019  ...        0.275185   \n",
      "4              513000.0                    0.028663  ...        0.033616   \n",
      "...                 ...                         ...  ...             ...   \n",
      "307506         225000.0                    0.032561  ...        0.316702   \n",
      "307507         225000.0                    0.025164  ...        0.001561   \n",
      "307508         585000.0                    0.005002  ...        0.153751   \n",
      "307509         319500.0                    0.005313  ...        0.135926   \n",
      "307510         675000.0                    0.046220  ...        0.355751   \n",
      "\n",
      "        EXT_SOURCE_2^2 EXT_SOURCE_3  EXT_SOURCE_2^2 DAYS_BIRTH  \\\n",
      "0                          0.009637                 654.152107   \n",
      "1                          0.207254                6491.237078   \n",
      "2                          0.225464                5885.942404   \n",
      "3                          0.226462                8040.528832   \n",
      "4                          0.055754                2076.117157   \n",
      "...                             ...                        ...   \n",
      "307506                     0.248701                4333.535804   \n",
      "307507                     0.007202                 279.510194   \n",
      "307508                     0.062812                4295.209004   \n",
      "307509                     0.174750                3162.050698   \n",
      "307510                     0.057197                8462.889915   \n",
      "\n",
      "        EXT_SOURCE_2 EXT_SOURCE_3^2  EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH  \\\n",
      "0                          0.005108                            346.733022   \n",
      "1                          0.178286                           5583.975307   \n",
      "2                          0.295894                           7724.580288   \n",
      "3                          0.186365                           6616.894625   \n",
      "4                          0.092471                           3443.335521   \n",
      "...                             ...                                   ...   \n",
      "307506                     0.195302                           3403.064320   \n",
      "307507                     0.033234                           1289.874083   \n",
      "307508                     0.025661                           1754.727146   \n",
      "307509                     0.224665                           4065.229651   \n",
      "307510                     0.009196                           1360.647784   \n",
      "\n",
      "        EXT_SOURCE_2 DAYS_BIRTH^2  EXT_SOURCE_3^3  EXT_SOURCE_3^2 DAYS_BIRTH  \\\n",
      "0                    2.353667e+07        0.002707                 183.785678   \n",
      "1                    1.748916e+08        0.153368                4803.518937   \n",
      "2                    2.016572e+08        0.388325               10137.567875   \n",
      "3                    2.349331e+08        0.153368                5445.325225   \n",
      "4                    1.282190e+08        0.153368                5710.929881   \n",
      "...                           ...             ...                        ...   \n",
      "307506               5.929720e+07        0.153368                2672.378236   \n",
      "307507               5.006225e+07        0.153368                5952.466801   \n",
      "307508               1.199916e+08        0.010483                 716.860892   \n",
      "307509               7.355897e+07        0.288836                5226.384299   \n",
      "307510               2.013220e+08        0.001479                 218.762433   \n",
      "\n",
      "        EXT_SOURCE_3 DAYS_BIRTH^2  DAYS_BIRTH^3  \n",
      "0                    1.247560e+07  8.468590e+11  \n",
      "1                    1.504475e+08  4.712058e+12  \n",
      "2                    2.646504e+08  6.908939e+12  \n",
      "3                    1.933364e+08  6.864416e+12  \n",
      "4                    2.126570e+08  7.918677e+12  \n",
      "...                           ...           ...  \n",
      "307506               4.656525e+07  8.113830e+11  \n",
      "307507               2.310256e+08  8.966503e+12  \n",
      "307508               4.902031e+07  3.352102e+12  \n",
      "307509               9.456968e+07  1.711207e+12  \n",
      "307510               3.236817e+07  4.789207e+12  \n",
      "\n",
      "[307511 rows x 275 columns]        SK_ID_CURR  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
      "0          100001                   0             0                1   \n",
      "1          100005                   0             0                1   \n",
      "2          100013                   0             1                1   \n",
      "3          100028                   0             0                1   \n",
      "4          100038                   0             1                0   \n",
      "...           ...                 ...           ...              ...   \n",
      "48739      456221                   0             0                1   \n",
      "48740      456222                   0             0                0   \n",
      "48741      456223                   0             1                1   \n",
      "48742      456224                   0             0                0   \n",
      "48743      456250                   0             1                0   \n",
      "\n",
      "       CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
      "0                 0          135000.0    568800.0      20560.5   \n",
      "1                 0           99000.0    222768.0      17370.0   \n",
      "2                 0          202500.0    663264.0      69777.0   \n",
      "3                 2          315000.0   1575000.0      49018.5   \n",
      "4                 1          180000.0    625500.0      32067.0   \n",
      "...             ...               ...         ...          ...   \n",
      "48739             0          121500.0    412560.0      17473.5   \n",
      "48740             2          157500.0    622413.0      31909.5   \n",
      "48741             1          202500.0    315000.0      33205.5   \n",
      "48742             0          225000.0    450000.0      25128.0   \n",
      "48743             0          135000.0    312768.0      24709.5   \n",
      "\n",
      "       AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  ...  EXT_SOURCE_2^3  \\\n",
      "0             450000.0                    0.018850  ...        0.492392   \n",
      "1             180000.0                    0.035792  ...        0.024809   \n",
      "2             630000.0                    0.019101  ...        0.342687   \n",
      "3            1575000.0                    0.026392  ...        0.132399   \n",
      "4             625500.0                    0.010032  ...        0.077139   \n",
      "...                ...                         ...  ...             ...   \n",
      "48739         270000.0                    0.002042  ...        0.272823   \n",
      "48740         495000.0                    0.035792  ...        0.320850   \n",
      "48741         315000.0                    0.026392  ...        0.253359   \n",
      "48742         450000.0                    0.018850  ...        0.088538   \n",
      "48743         270000.0                    0.006629  ...        0.095156   \n",
      "\n",
      "       EXT_SOURCE_2^2 EXT_SOURCE_3  EXT_SOURCE_2^2 DAYS_BIRTH  \\\n",
      "0                         0.099469               11997.802403   \n",
      "1                         0.036829                1536.577117   \n",
      "2                         0.299203                9812.640816   \n",
      "3                         0.159163                3630.555667   \n",
      "4                         0.096997                2362.974127   \n",
      "...                            ...                        ...   \n",
      "48739                     0.270488                8400.368742   \n",
      "48740                     0.250869                5242.555692   \n",
      "48741                     0.113597                6375.125880   \n",
      "48742                     0.118287                2774.734348   \n",
      "48743                     0.056721                2910.091018   \n",
      "\n",
      "       EXT_SOURCE_2 EXT_SOURCE_3^2  EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH  \\\n",
      "0                         0.020094                           2423.698322   \n",
      "1                         0.054673                           2281.043619   \n",
      "2                         0.261238                           8567.521115   \n",
      "3                         0.191336                           4364.443591   \n",
      "4                         0.121968                           2971.298294   \n",
      "...                            ...                                   ...   \n",
      "48739                     0.268174                           8328.493414   \n",
      "48740                     0.196151                           4099.084854   \n",
      "48741                     0.050933                           2858.384957   \n",
      "48742                     0.158031                           3707.043157   \n",
      "48743                     0.033810                           1734.640191   \n",
      "\n",
      "       EXT_SOURCE_2 DAYS_BIRTH^2  EXT_SOURCE_3^3  EXT_SOURCE_3^2 DAYS_BIRTH  \\\n",
      "0                   2.923427e+08        0.004059                 489.615795   \n",
      "1                   9.516956e+07        0.081161                3386.201665   \n",
      "2                   2.809794e+08        0.228089                7480.393855   \n",
      "3                   9.955450e+07        0.230013                5246.681115   \n",
      "4                   7.238455e+07        0.153368                3736.229463   \n",
      "...                          ...             ...                        ...   \n",
      "48739               2.586523e+08        0.265879                8257.233066   \n",
      "48740               8.566112e+07        0.153368                3205.020151   \n",
      "48741               1.604135e+08        0.022837                1281.600508   \n",
      "48742               8.695850e+07        0.211130                4952.607075   \n",
      "48743               8.899687e+07        0.020153                1033.980235   \n",
      "\n",
      "       EXT_SOURCE_3 DAYS_BIRTH^2  DAYS_BIRTH^3  \n",
      "0                   5.905670e+07  7.123328e+12  \n",
      "1                   1.412789e+08  5.894429e+12  \n",
      "2                   2.453261e+08  8.045687e+12  \n",
      "3                   1.196786e+08  2.729912e+12  \n",
      "4                   9.101923e+07  2.217342e+12  \n",
      "...                          ...           ...  \n",
      "48739               2.564392e+08  7.964054e+12  \n",
      "48740               6.697730e+07  1.399666e+12  \n",
      "48741               7.192382e+07  4.036388e+12  \n",
      "48742               1.161765e+08  2.725227e+12  \n",
      "48743               5.304904e+07  2.721717e+12  \n",
      "\n",
      "[48744 rows x 275 columns]\n"
     ]
    }
   ],
   "source": [
    "# Put test features into dataframe\n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n",
    "                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Merge polynomial features into training dataframe\n",
    "poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']   # .merge method를 사용하기 위해 기준이 필요해 추가해준 것.\n",
    "print(poly_features.shape)   # poly_features의 행렬을 파악하기 위해서 shape method 사용.\n",
    "app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')   # 'SK_ID_CURR을 기준으로 app_train 왼쪽에 poly_features 병합'\n",
    "\n",
    "# Merge polnomial features into testing dataframe\n",
    "poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\n",
    "print(poly_features_test.shape)\n",
    "app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')   # 위와 동일\n",
    "\n",
    "# Align the dataframes\n",
    "app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)   # .align method를 통해서 app_train_poly 자료 내의 target 변수 제거\n",
    "\n",
    "# Print out the new shapes\n",
    "print('Training data with polynomial features shape: ', app_train_poly.shape)\n",
    "print('Testing data with polynomial features shape:  ', app_test_poly.shape)\n",
    "print(app_train_poly, app_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 보면 poly_train_poly의 변수가 37개로 돼있는데 target과 SK_ID_CURR이 추가됐기 때문. poly_features_test는 SK_ID_CURR만 추가되서 36개로 나타났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train_domain = app_train.copy()\n",
    "app_test_domain = app_test.copy()\n",
    "\n",
    "app_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_INCOME_TOTAL']\n",
    "app_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY'] / app_train_domain['AMT_CREDIT']\n",
    "app_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED'] / app_train_domain['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\n",
    "app_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\n",
    "app_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg2_train_t = app_train_domain['TARGET']\n",
    "kg2_train_f = app_train_domain.drop(['TARGET'], axis=1)\n",
    "kg2_test_f = app_test_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비율을 나타내는 새로운 변수들을 생성후 데이터에 추가해줬고 이를 통해 train data와 test data를 생성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg3_train_t = kg1_train_t\n",
    "kg3_train_f = app_train_poly\n",
    "kg3_test_f = app_test_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 다항 변환한 변수들을 추가한 데이터로 train data와 test data를 생성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 240)\n",
      "(307511, 244)\n",
      "(307511, 275)\n",
      "\n",
      "(48744, 240)\n",
      "(48744, 244)\n",
      "(48744, 275)\n"
     ]
    }
   ],
   "source": [
    "print(kg1_train_f.shape)\n",
    "print(kg2_train_f.shape)\n",
    "print(kg3_train_f.shape)\n",
    "print()\n",
    "\n",
    "print(kg1_test_f.shape)\n",
    "print(kg2_test_f.shape)\n",
    "print(kg3_test_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 대체\n",
    "누락된 값은 변수의 중앙값으로 대체하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer   # SimpleImputer는 결측치를 간편하게 처리해주는 클래스.\n",
    "from sklearn.model_selection import train_test_split\n",
    "imputer = SimpleImputer(strategy = 'median')   # 결측치 중앙값으로 입력.\n",
    "\n",
    "# Median imputation of missing values\n",
    "imputer1 = SimpleImputer(strategy = 'median')  # 결측치를 중앙값으로 대체하는 객체 생성.\n",
    "imputer2 = SimpleImputer(strategy = 'median')\n",
    "imputer3 = SimpleImputer(strategy = 'median')\n",
    "\n",
    "# Fit on the training data\n",
    "imputer1.fit(kg1_train_f)   # 결측치를 처리하지 않은 데이터를 중앙값으로 대체해준다.\n",
    "imputer2.fit(kg2_train_f)\n",
    "imputer3.fit(kg3_train_f)\n",
    "\n",
    "# Transform both training and testing data\n",
    "kg1m_train_f = imputer1.transform(kg1_train_f)\n",
    "kg1m_test_f = imputer1.transform(kg1_test_f)\n",
    "# kg1_test_t는 target으로 0과 1으로 이뤄져있고 결측치가 없어서 imputer가 필요 없다.\n",
    "\n",
    "kg2m_train_f = imputer2.transform(kg2_train_f)\n",
    "kg2m_test_f = imputer2.transform(kg2_test_f)\n",
    "\n",
    "kg3m_train_f = imputer3.transform(kg3_train_f)\n",
    "kg3m_test_f = imputer3.transform(kg3_test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "decision_tree5 = DecisionTreeClassifier(max_depth=1, random_state=5)\n",
    "decision_tree5.fit(kg1m_train_f, kg1_train_t)\n",
    "decision_tree5_pred = decision_tree5.predict(kg1m_test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.278824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.277197\n",
      "[3]\ttraining's binary_logloss: 0.275904\n",
      "[4]\ttraining's binary_logloss: 0.274642\n",
      "[5]\ttraining's binary_logloss: 0.27357\n",
      "[6]\ttraining's binary_logloss: 0.272557\n",
      "[7]\ttraining's binary_logloss: 0.271648\n",
      "[8]\ttraining's binary_logloss: 0.270755\n",
      "[9]\ttraining's binary_logloss: 0.269956\n",
      "[10]\ttraining's binary_logloss: 0.269223\n",
      "[11]\ttraining's binary_logloss: 0.268572\n",
      "[12]\ttraining's binary_logloss: 0.267963\n",
      "[13]\ttraining's binary_logloss: 0.26739\n",
      "[14]\ttraining's binary_logloss: 0.266836\n",
      "[15]\ttraining's binary_logloss: 0.266337\n",
      "[16]\ttraining's binary_logloss: 0.265876\n",
      "[17]\ttraining's binary_logloss: 0.265444\n",
      "[18]\ttraining's binary_logloss: 0.26503\n",
      "[19]\ttraining's binary_logloss: 0.264629\n",
      "[20]\ttraining's binary_logloss: 0.264247\n",
      "[21]\ttraining's binary_logloss: 0.263886\n",
      "[22]\ttraining's binary_logloss: 0.263546\n",
      "[23]\ttraining's binary_logloss: 0.263214\n",
      "[24]\ttraining's binary_logloss: 0.262898\n",
      "[25]\ttraining's binary_logloss: 0.262588\n",
      "[26]\ttraining's binary_logloss: 0.262291\n",
      "[27]\ttraining's binary_logloss: 0.262003\n",
      "[28]\ttraining's binary_logloss: 0.261731\n",
      "[29]\ttraining's binary_logloss: 0.261482\n",
      "[30]\ttraining's binary_logloss: 0.261237\n",
      "[31]\ttraining's binary_logloss: 0.260999\n",
      "[32]\ttraining's binary_logloss: 0.260768\n",
      "[33]\ttraining's binary_logloss: 0.260545\n",
      "[34]\ttraining's binary_logloss: 0.260329\n",
      "[35]\ttraining's binary_logloss: 0.260123\n",
      "[36]\ttraining's binary_logloss: 0.259926\n",
      "[37]\ttraining's binary_logloss: 0.259736\n",
      "[38]\ttraining's binary_logloss: 0.25955\n",
      "[39]\ttraining's binary_logloss: 0.259368\n",
      "[40]\ttraining's binary_logloss: 0.259188\n",
      "[41]\ttraining's binary_logloss: 0.259018\n",
      "[42]\ttraining's binary_logloss: 0.258852\n",
      "[43]\ttraining's binary_logloss: 0.258688\n",
      "[44]\ttraining's binary_logloss: 0.258529\n",
      "[45]\ttraining's binary_logloss: 0.25838\n",
      "[46]\ttraining's binary_logloss: 0.258236\n",
      "[47]\ttraining's binary_logloss: 0.258092\n",
      "[48]\ttraining's binary_logloss: 0.257955\n",
      "[49]\ttraining's binary_logloss: 0.257817\n",
      "[50]\ttraining's binary_logloss: 0.257683\n",
      "[51]\ttraining's binary_logloss: 0.257552\n",
      "[52]\ttraining's binary_logloss: 0.257422\n",
      "[53]\ttraining's binary_logloss: 0.257295\n",
      "[54]\ttraining's binary_logloss: 0.257178\n",
      "[55]\ttraining's binary_logloss: 0.257066\n",
      "[56]\ttraining's binary_logloss: 0.256956\n",
      "[57]\ttraining's binary_logloss: 0.256848\n",
      "[58]\ttraining's binary_logloss: 0.256741\n",
      "[59]\ttraining's binary_logloss: 0.256635\n",
      "[60]\ttraining's binary_logloss: 0.256532\n",
      "[61]\ttraining's binary_logloss: 0.25643\n",
      "[62]\ttraining's binary_logloss: 0.25633\n",
      "[63]\ttraining's binary_logloss: 0.256237\n",
      "[64]\ttraining's binary_logloss: 0.256143\n",
      "[65]\ttraining's binary_logloss: 0.256053\n",
      "[66]\ttraining's binary_logloss: 0.255964\n",
      "[67]\ttraining's binary_logloss: 0.255878\n",
      "[68]\ttraining's binary_logloss: 0.255795\n",
      "[69]\ttraining's binary_logloss: 0.255711\n",
      "[70]\ttraining's binary_logloss: 0.255629\n",
      "[71]\ttraining's binary_logloss: 0.255548\n",
      "[72]\ttraining's binary_logloss: 0.255468\n",
      "[73]\ttraining's binary_logloss: 0.255388\n",
      "[74]\ttraining's binary_logloss: 0.255311\n",
      "[75]\ttraining's binary_logloss: 0.255235\n",
      "[76]\ttraining's binary_logloss: 0.255162\n",
      "[77]\ttraining's binary_logloss: 0.255091\n",
      "[78]\ttraining's binary_logloss: 0.25502\n",
      "[79]\ttraining's binary_logloss: 0.25495\n",
      "[80]\ttraining's binary_logloss: 0.254881\n",
      "[81]\ttraining's binary_logloss: 0.254814\n",
      "[82]\ttraining's binary_logloss: 0.254749\n",
      "[83]\ttraining's binary_logloss: 0.254686\n",
      "[84]\ttraining's binary_logloss: 0.254624\n",
      "[85]\ttraining's binary_logloss: 0.254563\n",
      "[86]\ttraining's binary_logloss: 0.254501\n",
      "[87]\ttraining's binary_logloss: 0.254439\n",
      "[88]\ttraining's binary_logloss: 0.254379\n",
      "[89]\ttraining's binary_logloss: 0.254319\n",
      "[90]\ttraining's binary_logloss: 0.254259\n",
      "[91]\ttraining's binary_logloss: 0.254201\n",
      "[92]\ttraining's binary_logloss: 0.254144\n",
      "[93]\ttraining's binary_logloss: 0.254087\n",
      "[94]\ttraining's binary_logloss: 0.254032\n",
      "[95]\ttraining's binary_logloss: 0.253974\n",
      "[96]\ttraining's binary_logloss: 0.253919\n",
      "[97]\ttraining's binary_logloss: 0.253865\n",
      "[98]\ttraining's binary_logloss: 0.253814\n",
      "[99]\ttraining's binary_logloss: 0.253763\n",
      "[100]\ttraining's binary_logloss: 0.253713\n",
      "[101]\ttraining's binary_logloss: 0.253664\n",
      "[102]\ttraining's binary_logloss: 0.253614\n",
      "[103]\ttraining's binary_logloss: 0.253561\n",
      "[104]\ttraining's binary_logloss: 0.253513\n",
      "[105]\ttraining's binary_logloss: 0.253466\n",
      "[106]\ttraining's binary_logloss: 0.253419\n",
      "[107]\ttraining's binary_logloss: 0.253373\n",
      "[108]\ttraining's binary_logloss: 0.253326\n",
      "[109]\ttraining's binary_logloss: 0.25328\n",
      "[110]\ttraining's binary_logloss: 0.253235\n",
      "[111]\ttraining's binary_logloss: 0.25319\n",
      "[112]\ttraining's binary_logloss: 0.253145\n",
      "[113]\ttraining's binary_logloss: 0.253102\n",
      "[114]\ttraining's binary_logloss: 0.253059\n",
      "[115]\ttraining's binary_logloss: 0.253016\n",
      "[116]\ttraining's binary_logloss: 0.252974\n",
      "[117]\ttraining's binary_logloss: 0.252933\n",
      "[118]\ttraining's binary_logloss: 0.252893\n",
      "[119]\ttraining's binary_logloss: 0.252853\n",
      "[120]\ttraining's binary_logloss: 0.252813\n",
      "[121]\ttraining's binary_logloss: 0.252773\n",
      "[122]\ttraining's binary_logloss: 0.252732\n",
      "[123]\ttraining's binary_logloss: 0.252693\n",
      "[124]\ttraining's binary_logloss: 0.252656\n",
      "[125]\ttraining's binary_logloss: 0.252617\n",
      "[126]\ttraining's binary_logloss: 0.25258\n",
      "[127]\ttraining's binary_logloss: 0.252543\n",
      "[128]\ttraining's binary_logloss: 0.252506\n",
      "[129]\ttraining's binary_logloss: 0.25247\n",
      "[130]\ttraining's binary_logloss: 0.252434\n",
      "[131]\ttraining's binary_logloss: 0.2524\n",
      "[132]\ttraining's binary_logloss: 0.252366\n",
      "[133]\ttraining's binary_logloss: 0.252332\n",
      "[134]\ttraining's binary_logloss: 0.252298\n",
      "[135]\ttraining's binary_logloss: 0.252265\n",
      "[136]\ttraining's binary_logloss: 0.252232\n",
      "[137]\ttraining's binary_logloss: 0.252199\n",
      "[138]\ttraining's binary_logloss: 0.252166\n",
      "[139]\ttraining's binary_logloss: 0.252133\n",
      "[140]\ttraining's binary_logloss: 0.2521\n",
      "[141]\ttraining's binary_logloss: 0.252069\n",
      "[142]\ttraining's binary_logloss: 0.252038\n",
      "[143]\ttraining's binary_logloss: 0.252008\n",
      "[144]\ttraining's binary_logloss: 0.251977\n",
      "[145]\ttraining's binary_logloss: 0.251945\n",
      "[146]\ttraining's binary_logloss: 0.251916\n",
      "[147]\ttraining's binary_logloss: 0.251886\n",
      "[148]\ttraining's binary_logloss: 0.251857\n",
      "[149]\ttraining's binary_logloss: 0.251828\n",
      "[150]\ttraining's binary_logloss: 0.2518\n",
      "[151]\ttraining's binary_logloss: 0.251772\n",
      "[152]\ttraining's binary_logloss: 0.251743\n",
      "[153]\ttraining's binary_logloss: 0.251715\n",
      "[154]\ttraining's binary_logloss: 0.251687\n",
      "[155]\ttraining's binary_logloss: 0.251659\n",
      "[156]\ttraining's binary_logloss: 0.251631\n",
      "[157]\ttraining's binary_logloss: 0.251604\n",
      "[158]\ttraining's binary_logloss: 0.251577\n",
      "[159]\ttraining's binary_logloss: 0.251551\n",
      "[160]\ttraining's binary_logloss: 0.251525\n",
      "[161]\ttraining's binary_logloss: 0.2515\n",
      "[162]\ttraining's binary_logloss: 0.251473\n",
      "[163]\ttraining's binary_logloss: 0.251448\n",
      "[164]\ttraining's binary_logloss: 0.251424\n",
      "[165]\ttraining's binary_logloss: 0.251399\n",
      "[166]\ttraining's binary_logloss: 0.251374\n",
      "[167]\ttraining's binary_logloss: 0.25135\n",
      "[168]\ttraining's binary_logloss: 0.251326\n",
      "[169]\ttraining's binary_logloss: 0.251302\n",
      "[170]\ttraining's binary_logloss: 0.251278\n",
      "[171]\ttraining's binary_logloss: 0.251255\n",
      "[172]\ttraining's binary_logloss: 0.251232\n",
      "[173]\ttraining's binary_logloss: 0.251208\n",
      "[174]\ttraining's binary_logloss: 0.251185\n",
      "[175]\ttraining's binary_logloss: 0.251162\n",
      "[176]\ttraining's binary_logloss: 0.25114\n",
      "[177]\ttraining's binary_logloss: 0.251117\n",
      "[178]\ttraining's binary_logloss: 0.251095\n",
      "[179]\ttraining's binary_logloss: 0.251072\n",
      "[180]\ttraining's binary_logloss: 0.25105\n",
      "[181]\ttraining's binary_logloss: 0.251028\n",
      "[182]\ttraining's binary_logloss: 0.251006\n",
      "[183]\ttraining's binary_logloss: 0.250985\n",
      "[184]\ttraining's binary_logloss: 0.250964\n",
      "[185]\ttraining's binary_logloss: 0.250943\n",
      "[186]\ttraining's binary_logloss: 0.250922\n",
      "[187]\ttraining's binary_logloss: 0.250901\n",
      "[188]\ttraining's binary_logloss: 0.250881\n",
      "[189]\ttraining's binary_logloss: 0.250861\n",
      "[190]\ttraining's binary_logloss: 0.250842\n",
      "[191]\ttraining's binary_logloss: 0.250822\n",
      "[192]\ttraining's binary_logloss: 0.250801\n",
      "[193]\ttraining's binary_logloss: 0.250782\n",
      "[194]\ttraining's binary_logloss: 0.250762\n",
      "[195]\ttraining's binary_logloss: 0.250743\n",
      "[196]\ttraining's binary_logloss: 0.250723\n",
      "[197]\ttraining's binary_logloss: 0.250704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198]\ttraining's binary_logloss: 0.250685\n",
      "[199]\ttraining's binary_logloss: 0.250666\n",
      "[200]\ttraining's binary_logloss: 0.250647\n",
      "[201]\ttraining's binary_logloss: 0.250628\n",
      "[202]\ttraining's binary_logloss: 0.250609\n",
      "[203]\ttraining's binary_logloss: 0.250591\n",
      "[204]\ttraining's binary_logloss: 0.250572\n",
      "[205]\ttraining's binary_logloss: 0.250554\n",
      "[206]\ttraining's binary_logloss: 0.250536\n",
      "[207]\ttraining's binary_logloss: 0.250518\n",
      "[208]\ttraining's binary_logloss: 0.2505\n",
      "[209]\ttraining's binary_logloss: 0.250482\n",
      "[210]\ttraining's binary_logloss: 0.250464\n",
      "[211]\ttraining's binary_logloss: 0.250447\n",
      "[212]\ttraining's binary_logloss: 0.250429\n",
      "[213]\ttraining's binary_logloss: 0.250412\n",
      "[214]\ttraining's binary_logloss: 0.250395\n",
      "[215]\ttraining's binary_logloss: 0.250378\n",
      "[216]\ttraining's binary_logloss: 0.250362\n",
      "[217]\ttraining's binary_logloss: 0.250345\n",
      "[218]\ttraining's binary_logloss: 0.250329\n",
      "[219]\ttraining's binary_logloss: 0.250312\n",
      "[220]\ttraining's binary_logloss: 0.250296\n",
      "[221]\ttraining's binary_logloss: 0.250279\n",
      "[222]\ttraining's binary_logloss: 0.250263\n",
      "[223]\ttraining's binary_logloss: 0.250248\n",
      "[224]\ttraining's binary_logloss: 0.250232\n",
      "[225]\ttraining's binary_logloss: 0.250216\n",
      "[226]\ttraining's binary_logloss: 0.250201\n",
      "[227]\ttraining's binary_logloss: 0.250185\n",
      "[228]\ttraining's binary_logloss: 0.25017\n",
      "[229]\ttraining's binary_logloss: 0.250154\n",
      "[230]\ttraining's binary_logloss: 0.250139\n",
      "[231]\ttraining's binary_logloss: 0.250124\n",
      "[232]\ttraining's binary_logloss: 0.250109\n",
      "[233]\ttraining's binary_logloss: 0.250095\n",
      "[234]\ttraining's binary_logloss: 0.25008\n",
      "[235]\ttraining's binary_logloss: 0.250066\n",
      "[236]\ttraining's binary_logloss: 0.250051\n",
      "[237]\ttraining's binary_logloss: 0.250037\n",
      "[238]\ttraining's binary_logloss: 0.250022\n",
      "[239]\ttraining's binary_logloss: 0.250008\n",
      "[240]\ttraining's binary_logloss: 0.249994\n",
      "[241]\ttraining's binary_logloss: 0.249979\n",
      "[242]\ttraining's binary_logloss: 0.249965\n",
      "[243]\ttraining's binary_logloss: 0.249951\n",
      "[244]\ttraining's binary_logloss: 0.249937\n",
      "[245]\ttraining's binary_logloss: 0.249923\n",
      "[246]\ttraining's binary_logloss: 0.249909\n",
      "[247]\ttraining's binary_logloss: 0.249896\n",
      "[248]\ttraining's binary_logloss: 0.249882\n",
      "[249]\ttraining's binary_logloss: 0.249869\n",
      "[250]\ttraining's binary_logloss: 0.249856\n",
      "[251]\ttraining's binary_logloss: 0.249843\n",
      "[252]\ttraining's binary_logloss: 0.249829\n",
      "[253]\ttraining's binary_logloss: 0.249816\n",
      "[254]\ttraining's binary_logloss: 0.249803\n",
      "[255]\ttraining's binary_logloss: 0.249791\n",
      "[256]\ttraining's binary_logloss: 0.249778\n",
      "[257]\ttraining's binary_logloss: 0.249765\n",
      "[258]\ttraining's binary_logloss: 0.249753\n",
      "[259]\ttraining's binary_logloss: 0.24974\n",
      "[260]\ttraining's binary_logloss: 0.249727\n",
      "[261]\ttraining's binary_logloss: 0.249715\n",
      "[262]\ttraining's binary_logloss: 0.249703\n",
      "[263]\ttraining's binary_logloss: 0.249691\n",
      "[264]\ttraining's binary_logloss: 0.249679\n",
      "[265]\ttraining's binary_logloss: 0.249667\n",
      "[266]\ttraining's binary_logloss: 0.249656\n",
      "[267]\ttraining's binary_logloss: 0.249644\n",
      "[268]\ttraining's binary_logloss: 0.249632\n",
      "[269]\ttraining's binary_logloss: 0.249621\n",
      "[270]\ttraining's binary_logloss: 0.249609\n",
      "[271]\ttraining's binary_logloss: 0.249597\n",
      "[272]\ttraining's binary_logloss: 0.249586\n",
      "[273]\ttraining's binary_logloss: 0.249574\n",
      "[274]\ttraining's binary_logloss: 0.249562\n",
      "[275]\ttraining's binary_logloss: 0.249551\n",
      "[276]\ttraining's binary_logloss: 0.24954\n",
      "[277]\ttraining's binary_logloss: 0.249528\n",
      "[278]\ttraining's binary_logloss: 0.249517\n",
      "[279]\ttraining's binary_logloss: 0.249506\n",
      "[280]\ttraining's binary_logloss: 0.249495\n",
      "[281]\ttraining's binary_logloss: 0.249484\n",
      "[282]\ttraining's binary_logloss: 0.249473\n",
      "[283]\ttraining's binary_logloss: 0.249463\n",
      "[284]\ttraining's binary_logloss: 0.249452\n",
      "[285]\ttraining's binary_logloss: 0.249441\n",
      "[286]\ttraining's binary_logloss: 0.24943\n",
      "[287]\ttraining's binary_logloss: 0.24942\n",
      "[288]\ttraining's binary_logloss: 0.249409\n",
      "[289]\ttraining's binary_logloss: 0.249399\n",
      "[290]\ttraining's binary_logloss: 0.249388\n",
      "[291]\ttraining's binary_logloss: 0.249378\n",
      "[292]\ttraining's binary_logloss: 0.249366\n",
      "[293]\ttraining's binary_logloss: 0.249356\n",
      "[294]\ttraining's binary_logloss: 0.249346\n",
      "[295]\ttraining's binary_logloss: 0.249336\n",
      "[296]\ttraining's binary_logloss: 0.249326\n",
      "[297]\ttraining's binary_logloss: 0.249315\n",
      "[298]\ttraining's binary_logloss: 0.249305\n",
      "[299]\ttraining's binary_logloss: 0.249295\n",
      "[300]\ttraining's binary_logloss: 0.249285\n",
      "[301]\ttraining's binary_logloss: 0.249275\n",
      "[302]\ttraining's binary_logloss: 0.249264\n",
      "[303]\ttraining's binary_logloss: 0.249254\n",
      "[304]\ttraining's binary_logloss: 0.249245\n",
      "[305]\ttraining's binary_logloss: 0.249235\n",
      "[306]\ttraining's binary_logloss: 0.249225\n",
      "[307]\ttraining's binary_logloss: 0.249215\n",
      "[308]\ttraining's binary_logloss: 0.249206\n",
      "[309]\ttraining's binary_logloss: 0.249196\n",
      "[310]\ttraining's binary_logloss: 0.249187\n",
      "[311]\ttraining's binary_logloss: 0.249177\n",
      "[312]\ttraining's binary_logloss: 0.249168\n",
      "[313]\ttraining's binary_logloss: 0.249159\n",
      "[314]\ttraining's binary_logloss: 0.24915\n",
      "[315]\ttraining's binary_logloss: 0.249139\n",
      "[316]\ttraining's binary_logloss: 0.24913\n",
      "[317]\ttraining's binary_logloss: 0.249121\n",
      "[318]\ttraining's binary_logloss: 0.249112\n",
      "[319]\ttraining's binary_logloss: 0.249103\n",
      "[320]\ttraining's binary_logloss: 0.249094\n",
      "[321]\ttraining's binary_logloss: 0.249085\n",
      "[322]\ttraining's binary_logloss: 0.249076\n",
      "[323]\ttraining's binary_logloss: 0.249066\n",
      "[324]\ttraining's binary_logloss: 0.249057\n",
      "[325]\ttraining's binary_logloss: 0.249048\n",
      "[326]\ttraining's binary_logloss: 0.249039\n",
      "[327]\ttraining's binary_logloss: 0.24903\n",
      "[328]\ttraining's binary_logloss: 0.249021\n",
      "[329]\ttraining's binary_logloss: 0.249013\n",
      "[330]\ttraining's binary_logloss: 0.249004\n",
      "[331]\ttraining's binary_logloss: 0.248995\n",
      "[332]\ttraining's binary_logloss: 0.248986\n",
      "[333]\ttraining's binary_logloss: 0.248977\n",
      "[334]\ttraining's binary_logloss: 0.248969\n",
      "[335]\ttraining's binary_logloss: 0.24896\n",
      "[336]\ttraining's binary_logloss: 0.248952\n",
      "[337]\ttraining's binary_logloss: 0.248943\n",
      "[338]\ttraining's binary_logloss: 0.248935\n",
      "[339]\ttraining's binary_logloss: 0.248926\n",
      "[340]\ttraining's binary_logloss: 0.248918\n",
      "[341]\ttraining's binary_logloss: 0.24891\n",
      "[342]\ttraining's binary_logloss: 0.248902\n",
      "[343]\ttraining's binary_logloss: 0.248894\n",
      "[344]\ttraining's binary_logloss: 0.248885\n",
      "[345]\ttraining's binary_logloss: 0.248877\n",
      "[346]\ttraining's binary_logloss: 0.248869\n",
      "[347]\ttraining's binary_logloss: 0.248861\n",
      "[348]\ttraining's binary_logloss: 0.248853\n",
      "[349]\ttraining's binary_logloss: 0.248845\n",
      "[350]\ttraining's binary_logloss: 0.248837\n",
      "[351]\ttraining's binary_logloss: 0.248829\n",
      "[352]\ttraining's binary_logloss: 0.248821\n",
      "[353]\ttraining's binary_logloss: 0.248813\n",
      "[354]\ttraining's binary_logloss: 0.248805\n",
      "[355]\ttraining's binary_logloss: 0.248797\n",
      "[356]\ttraining's binary_logloss: 0.24879\n",
      "[357]\ttraining's binary_logloss: 0.248782\n",
      "[358]\ttraining's binary_logloss: 0.248774\n",
      "[359]\ttraining's binary_logloss: 0.248767\n",
      "[360]\ttraining's binary_logloss: 0.248759\n",
      "[361]\ttraining's binary_logloss: 0.248751\n",
      "[362]\ttraining's binary_logloss: 0.248744\n",
      "[363]\ttraining's binary_logloss: 0.248736\n",
      "[364]\ttraining's binary_logloss: 0.248728\n",
      "[365]\ttraining's binary_logloss: 0.24872\n",
      "[366]\ttraining's binary_logloss: 0.248713\n",
      "[367]\ttraining's binary_logloss: 0.248705\n",
      "[368]\ttraining's binary_logloss: 0.248698\n",
      "[369]\ttraining's binary_logloss: 0.24869\n",
      "[370]\ttraining's binary_logloss: 0.248683\n",
      "[371]\ttraining's binary_logloss: 0.248676\n",
      "[372]\ttraining's binary_logloss: 0.248668\n",
      "[373]\ttraining's binary_logloss: 0.248661\n",
      "[374]\ttraining's binary_logloss: 0.248654\n",
      "[375]\ttraining's binary_logloss: 0.248647\n",
      "[376]\ttraining's binary_logloss: 0.24864\n",
      "[377]\ttraining's binary_logloss: 0.248632\n",
      "[378]\ttraining's binary_logloss: 0.248625\n",
      "[379]\ttraining's binary_logloss: 0.248618\n",
      "[380]\ttraining's binary_logloss: 0.248611\n",
      "[381]\ttraining's binary_logloss: 0.248604\n",
      "[382]\ttraining's binary_logloss: 0.248597\n",
      "[383]\ttraining's binary_logloss: 0.24859\n",
      "[384]\ttraining's binary_logloss: 0.248583\n",
      "[385]\ttraining's binary_logloss: 0.248576\n",
      "[386]\ttraining's binary_logloss: 0.248569\n",
      "[387]\ttraining's binary_logloss: 0.248563\n",
      "[388]\ttraining's binary_logloss: 0.248556\n",
      "[389]\ttraining's binary_logloss: 0.248549\n",
      "[390]\ttraining's binary_logloss: 0.248542\n",
      "[391]\ttraining's binary_logloss: 0.248536\n",
      "[392]\ttraining's binary_logloss: 0.248529\n",
      "[393]\ttraining's binary_logloss: 0.248522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394]\ttraining's binary_logloss: 0.248516\n",
      "[395]\ttraining's binary_logloss: 0.248509\n",
      "[396]\ttraining's binary_logloss: 0.248503\n",
      "[397]\ttraining's binary_logloss: 0.248496\n",
      "[398]\ttraining's binary_logloss: 0.248489\n",
      "[399]\ttraining's binary_logloss: 0.248483\n",
      "[400]\ttraining's binary_logloss: 0.248476\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.248476\n",
      "[1]\ttraining's binary_logloss: 0.278824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.277197\n",
      "[3]\ttraining's binary_logloss: 0.275904\n",
      "[4]\ttraining's binary_logloss: 0.274642\n",
      "[5]\ttraining's binary_logloss: 0.27357\n",
      "[6]\ttraining's binary_logloss: 0.272557\n",
      "[7]\ttraining's binary_logloss: 0.271648\n",
      "[8]\ttraining's binary_logloss: 0.270755\n",
      "[9]\ttraining's binary_logloss: 0.269956\n",
      "[10]\ttraining's binary_logloss: 0.269223\n",
      "[11]\ttraining's binary_logloss: 0.268572\n",
      "[12]\ttraining's binary_logloss: 0.267963\n",
      "[13]\ttraining's binary_logloss: 0.26739\n",
      "[14]\ttraining's binary_logloss: 0.266836\n",
      "[15]\ttraining's binary_logloss: 0.266337\n",
      "[16]\ttraining's binary_logloss: 0.265876\n",
      "[17]\ttraining's binary_logloss: 0.265444\n",
      "[18]\ttraining's binary_logloss: 0.26503\n",
      "[19]\ttraining's binary_logloss: 0.264629\n",
      "[20]\ttraining's binary_logloss: 0.264247\n",
      "[21]\ttraining's binary_logloss: 0.263886\n",
      "[22]\ttraining's binary_logloss: 0.263546\n",
      "[23]\ttraining's binary_logloss: 0.263214\n",
      "[24]\ttraining's binary_logloss: 0.262898\n",
      "[25]\ttraining's binary_logloss: 0.262588\n",
      "[26]\ttraining's binary_logloss: 0.262291\n",
      "[27]\ttraining's binary_logloss: 0.262003\n",
      "[28]\ttraining's binary_logloss: 0.261731\n",
      "[29]\ttraining's binary_logloss: 0.261482\n",
      "[30]\ttraining's binary_logloss: 0.261237\n",
      "[31]\ttraining's binary_logloss: 0.260999\n",
      "[32]\ttraining's binary_logloss: 0.260768\n",
      "[33]\ttraining's binary_logloss: 0.260545\n",
      "[34]\ttraining's binary_logloss: 0.260329\n",
      "[35]\ttraining's binary_logloss: 0.260123\n",
      "[36]\ttraining's binary_logloss: 0.259926\n",
      "[37]\ttraining's binary_logloss: 0.259736\n",
      "[38]\ttraining's binary_logloss: 0.25955\n",
      "[39]\ttraining's binary_logloss: 0.259368\n",
      "[40]\ttraining's binary_logloss: 0.259188\n",
      "[41]\ttraining's binary_logloss: 0.259018\n",
      "[42]\ttraining's binary_logloss: 0.258852\n",
      "[43]\ttraining's binary_logloss: 0.258688\n",
      "[44]\ttraining's binary_logloss: 0.258529\n",
      "[45]\ttraining's binary_logloss: 0.25838\n",
      "[46]\ttraining's binary_logloss: 0.258236\n",
      "[47]\ttraining's binary_logloss: 0.258092\n",
      "[48]\ttraining's binary_logloss: 0.257955\n",
      "[49]\ttraining's binary_logloss: 0.257817\n",
      "[50]\ttraining's binary_logloss: 0.257683\n",
      "[51]\ttraining's binary_logloss: 0.257552\n",
      "[52]\ttraining's binary_logloss: 0.257422\n",
      "[53]\ttraining's binary_logloss: 0.257293\n",
      "[54]\ttraining's binary_logloss: 0.257166\n",
      "[55]\ttraining's binary_logloss: 0.257049\n",
      "[56]\ttraining's binary_logloss: 0.256935\n",
      "[57]\ttraining's binary_logloss: 0.256822\n",
      "[58]\ttraining's binary_logloss: 0.25671\n",
      "[59]\ttraining's binary_logloss: 0.2566\n",
      "[60]\ttraining's binary_logloss: 0.256491\n",
      "[61]\ttraining's binary_logloss: 0.256384\n",
      "[62]\ttraining's binary_logloss: 0.256278\n",
      "[63]\ttraining's binary_logloss: 0.256176\n",
      "[64]\ttraining's binary_logloss: 0.256075\n",
      "[65]\ttraining's binary_logloss: 0.25598\n",
      "[66]\ttraining's binary_logloss: 0.255881\n",
      "[67]\ttraining's binary_logloss: 0.255788\n",
      "[68]\ttraining's binary_logloss: 0.255696\n",
      "[69]\ttraining's binary_logloss: 0.255606\n",
      "[70]\ttraining's binary_logloss: 0.255519\n",
      "[71]\ttraining's binary_logloss: 0.255432\n",
      "[72]\ttraining's binary_logloss: 0.255349\n",
      "[73]\ttraining's binary_logloss: 0.255266\n",
      "[74]\ttraining's binary_logloss: 0.255184\n",
      "[75]\ttraining's binary_logloss: 0.255099\n",
      "[76]\ttraining's binary_logloss: 0.255018\n",
      "[77]\ttraining's binary_logloss: 0.254935\n",
      "[78]\ttraining's binary_logloss: 0.254855\n",
      "[79]\ttraining's binary_logloss: 0.254778\n",
      "[80]\ttraining's binary_logloss: 0.2547\n",
      "[81]\ttraining's binary_logloss: 0.254624\n",
      "[82]\ttraining's binary_logloss: 0.254549\n",
      "[83]\ttraining's binary_logloss: 0.254475\n",
      "[84]\ttraining's binary_logloss: 0.254405\n",
      "[85]\ttraining's binary_logloss: 0.254335\n",
      "[86]\ttraining's binary_logloss: 0.254267\n",
      "[87]\ttraining's binary_logloss: 0.254198\n",
      "[88]\ttraining's binary_logloss: 0.25413\n",
      "[89]\ttraining's binary_logloss: 0.254065\n",
      "[90]\ttraining's binary_logloss: 0.253999\n",
      "[91]\ttraining's binary_logloss: 0.253934\n",
      "[92]\ttraining's binary_logloss: 0.253871\n",
      "[93]\ttraining's binary_logloss: 0.253806\n",
      "[94]\ttraining's binary_logloss: 0.253743\n",
      "[95]\ttraining's binary_logloss: 0.253683\n",
      "[96]\ttraining's binary_logloss: 0.253625\n",
      "[97]\ttraining's binary_logloss: 0.253567\n",
      "[98]\ttraining's binary_logloss: 0.253509\n",
      "[99]\ttraining's binary_logloss: 0.253452\n",
      "[100]\ttraining's binary_logloss: 0.253395\n",
      "[101]\ttraining's binary_logloss: 0.253339\n",
      "[102]\ttraining's binary_logloss: 0.253284\n",
      "[103]\ttraining's binary_logloss: 0.253229\n",
      "[104]\ttraining's binary_logloss: 0.253174\n",
      "[105]\ttraining's binary_logloss: 0.253118\n",
      "[106]\ttraining's binary_logloss: 0.253065\n",
      "[107]\ttraining's binary_logloss: 0.253014\n",
      "[108]\ttraining's binary_logloss: 0.252963\n",
      "[109]\ttraining's binary_logloss: 0.252913\n",
      "[110]\ttraining's binary_logloss: 0.252863\n",
      "[111]\ttraining's binary_logloss: 0.252814\n",
      "[112]\ttraining's binary_logloss: 0.252765\n",
      "[113]\ttraining's binary_logloss: 0.252717\n",
      "[114]\ttraining's binary_logloss: 0.252669\n",
      "[115]\ttraining's binary_logloss: 0.252623\n",
      "[116]\ttraining's binary_logloss: 0.252575\n",
      "[117]\ttraining's binary_logloss: 0.25253\n",
      "[118]\ttraining's binary_logloss: 0.252484\n",
      "[119]\ttraining's binary_logloss: 0.252439\n",
      "[120]\ttraining's binary_logloss: 0.252394\n",
      "[121]\ttraining's binary_logloss: 0.25235\n",
      "[122]\ttraining's binary_logloss: 0.252307\n",
      "[123]\ttraining's binary_logloss: 0.252265\n",
      "[124]\ttraining's binary_logloss: 0.252222\n",
      "[125]\ttraining's binary_logloss: 0.252178\n",
      "[126]\ttraining's binary_logloss: 0.252137\n",
      "[127]\ttraining's binary_logloss: 0.252096\n",
      "[128]\ttraining's binary_logloss: 0.252056\n",
      "[129]\ttraining's binary_logloss: 0.252016\n",
      "[130]\ttraining's binary_logloss: 0.251977\n",
      "[131]\ttraining's binary_logloss: 0.251938\n",
      "[132]\ttraining's binary_logloss: 0.251899\n",
      "[133]\ttraining's binary_logloss: 0.251861\n",
      "[134]\ttraining's binary_logloss: 0.251824\n",
      "[135]\ttraining's binary_logloss: 0.251787\n",
      "[136]\ttraining's binary_logloss: 0.251749\n",
      "[137]\ttraining's binary_logloss: 0.251712\n",
      "[138]\ttraining's binary_logloss: 0.251676\n",
      "[139]\ttraining's binary_logloss: 0.25164\n",
      "[140]\ttraining's binary_logloss: 0.251605\n",
      "[141]\ttraining's binary_logloss: 0.25157\n",
      "[142]\ttraining's binary_logloss: 0.251535\n",
      "[143]\ttraining's binary_logloss: 0.251501\n",
      "[144]\ttraining's binary_logloss: 0.251468\n",
      "[145]\ttraining's binary_logloss: 0.251435\n",
      "[146]\ttraining's binary_logloss: 0.251401\n",
      "[147]\ttraining's binary_logloss: 0.251369\n",
      "[148]\ttraining's binary_logloss: 0.251336\n",
      "[149]\ttraining's binary_logloss: 0.251304\n",
      "[150]\ttraining's binary_logloss: 0.251271\n",
      "[151]\ttraining's binary_logloss: 0.251239\n",
      "[152]\ttraining's binary_logloss: 0.251207\n",
      "[153]\ttraining's binary_logloss: 0.251176\n",
      "[154]\ttraining's binary_logloss: 0.251145\n",
      "[155]\ttraining's binary_logloss: 0.251115\n",
      "[156]\ttraining's binary_logloss: 0.251085\n",
      "[157]\ttraining's binary_logloss: 0.251055\n",
      "[158]\ttraining's binary_logloss: 0.251026\n",
      "[159]\ttraining's binary_logloss: 0.250997\n",
      "[160]\ttraining's binary_logloss: 0.250969\n",
      "[161]\ttraining's binary_logloss: 0.250939\n",
      "[162]\ttraining's binary_logloss: 0.250911\n",
      "[163]\ttraining's binary_logloss: 0.250883\n",
      "[164]\ttraining's binary_logloss: 0.250855\n",
      "[165]\ttraining's binary_logloss: 0.250826\n",
      "[166]\ttraining's binary_logloss: 0.250799\n",
      "[167]\ttraining's binary_logloss: 0.250772\n",
      "[168]\ttraining's binary_logloss: 0.250745\n",
      "[169]\ttraining's binary_logloss: 0.250718\n",
      "[170]\ttraining's binary_logloss: 0.250692\n",
      "[171]\ttraining's binary_logloss: 0.250665\n",
      "[172]\ttraining's binary_logloss: 0.250639\n",
      "[173]\ttraining's binary_logloss: 0.250614\n",
      "[174]\ttraining's binary_logloss: 0.250589\n",
      "[175]\ttraining's binary_logloss: 0.250564\n",
      "[176]\ttraining's binary_logloss: 0.250538\n",
      "[177]\ttraining's binary_logloss: 0.250513\n",
      "[178]\ttraining's binary_logloss: 0.250488\n",
      "[179]\ttraining's binary_logloss: 0.250465\n",
      "[180]\ttraining's binary_logloss: 0.250441\n",
      "[181]\ttraining's binary_logloss: 0.250418\n",
      "[182]\ttraining's binary_logloss: 0.250394\n",
      "[183]\ttraining's binary_logloss: 0.250371\n",
      "[184]\ttraining's binary_logloss: 0.250346\n",
      "[185]\ttraining's binary_logloss: 0.250323\n",
      "[186]\ttraining's binary_logloss: 0.250301\n",
      "[187]\ttraining's binary_logloss: 0.250278\n",
      "[188]\ttraining's binary_logloss: 0.250256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189]\ttraining's binary_logloss: 0.250233\n",
      "[190]\ttraining's binary_logloss: 0.250211\n",
      "[191]\ttraining's binary_logloss: 0.250188\n",
      "[192]\ttraining's binary_logloss: 0.250166\n",
      "[193]\ttraining's binary_logloss: 0.250145\n",
      "[194]\ttraining's binary_logloss: 0.250123\n",
      "[195]\ttraining's binary_logloss: 0.250102\n",
      "[196]\ttraining's binary_logloss: 0.250082\n",
      "[197]\ttraining's binary_logloss: 0.250061\n",
      "[198]\ttraining's binary_logloss: 0.250041\n",
      "[199]\ttraining's binary_logloss: 0.25002\n",
      "[200]\ttraining's binary_logloss: 0.249999\n",
      "[201]\ttraining's binary_logloss: 0.249979\n",
      "[202]\ttraining's binary_logloss: 0.249959\n",
      "[203]\ttraining's binary_logloss: 0.249939\n",
      "[204]\ttraining's binary_logloss: 0.24992\n",
      "[205]\ttraining's binary_logloss: 0.2499\n",
      "[206]\ttraining's binary_logloss: 0.24988\n",
      "[207]\ttraining's binary_logloss: 0.249861\n",
      "[208]\ttraining's binary_logloss: 0.249842\n",
      "[209]\ttraining's binary_logloss: 0.249822\n",
      "[210]\ttraining's binary_logloss: 0.249803\n",
      "[211]\ttraining's binary_logloss: 0.249784\n",
      "[212]\ttraining's binary_logloss: 0.249765\n",
      "[213]\ttraining's binary_logloss: 0.249746\n",
      "[214]\ttraining's binary_logloss: 0.249727\n",
      "[215]\ttraining's binary_logloss: 0.249709\n",
      "[216]\ttraining's binary_logloss: 0.24969\n",
      "[217]\ttraining's binary_logloss: 0.249672\n",
      "[218]\ttraining's binary_logloss: 0.249653\n",
      "[219]\ttraining's binary_logloss: 0.249636\n",
      "[220]\ttraining's binary_logloss: 0.249618\n",
      "[221]\ttraining's binary_logloss: 0.2496\n",
      "[222]\ttraining's binary_logloss: 0.249582\n",
      "[223]\ttraining's binary_logloss: 0.249565\n",
      "[224]\ttraining's binary_logloss: 0.249547\n",
      "[225]\ttraining's binary_logloss: 0.24953\n",
      "[226]\ttraining's binary_logloss: 0.249513\n",
      "[227]\ttraining's binary_logloss: 0.249497\n",
      "[228]\ttraining's binary_logloss: 0.24948\n",
      "[229]\ttraining's binary_logloss: 0.249463\n",
      "[230]\ttraining's binary_logloss: 0.249447\n",
      "[231]\ttraining's binary_logloss: 0.24943\n",
      "[232]\ttraining's binary_logloss: 0.249413\n",
      "[233]\ttraining's binary_logloss: 0.249397\n",
      "[234]\ttraining's binary_logloss: 0.24938\n",
      "[235]\ttraining's binary_logloss: 0.249364\n",
      "[236]\ttraining's binary_logloss: 0.249348\n",
      "[237]\ttraining's binary_logloss: 0.249332\n",
      "[238]\ttraining's binary_logloss: 0.249317\n",
      "[239]\ttraining's binary_logloss: 0.249301\n",
      "[240]\ttraining's binary_logloss: 0.249286\n",
      "[241]\ttraining's binary_logloss: 0.24927\n",
      "[242]\ttraining's binary_logloss: 0.249255\n",
      "[243]\ttraining's binary_logloss: 0.24924\n",
      "[244]\ttraining's binary_logloss: 0.249224\n",
      "[245]\ttraining's binary_logloss: 0.249209\n",
      "[246]\ttraining's binary_logloss: 0.249194\n",
      "[247]\ttraining's binary_logloss: 0.24918\n",
      "[248]\ttraining's binary_logloss: 0.249165\n",
      "[249]\ttraining's binary_logloss: 0.249151\n",
      "[250]\ttraining's binary_logloss: 0.249137\n",
      "[251]\ttraining's binary_logloss: 0.249123\n",
      "[252]\ttraining's binary_logloss: 0.249108\n",
      "[253]\ttraining's binary_logloss: 0.249094\n",
      "[254]\ttraining's binary_logloss: 0.24908\n",
      "[255]\ttraining's binary_logloss: 0.249066\n",
      "[256]\ttraining's binary_logloss: 0.249052\n",
      "[257]\ttraining's binary_logloss: 0.249038\n",
      "[258]\ttraining's binary_logloss: 0.249025\n",
      "[259]\ttraining's binary_logloss: 0.249011\n",
      "[260]\ttraining's binary_logloss: 0.248997\n",
      "[261]\ttraining's binary_logloss: 0.248983\n",
      "[262]\ttraining's binary_logloss: 0.248969\n",
      "[263]\ttraining's binary_logloss: 0.248956\n",
      "[264]\ttraining's binary_logloss: 0.248942\n",
      "[265]\ttraining's binary_logloss: 0.248929\n",
      "[266]\ttraining's binary_logloss: 0.248916\n",
      "[267]\ttraining's binary_logloss: 0.248903\n",
      "[268]\ttraining's binary_logloss: 0.24889\n",
      "[269]\ttraining's binary_logloss: 0.248877\n",
      "[270]\ttraining's binary_logloss: 0.248864\n",
      "[271]\ttraining's binary_logloss: 0.248851\n",
      "[272]\ttraining's binary_logloss: 0.248838\n",
      "[273]\ttraining's binary_logloss: 0.248825\n",
      "[274]\ttraining's binary_logloss: 0.248813\n",
      "[275]\ttraining's binary_logloss: 0.2488\n",
      "[276]\ttraining's binary_logloss: 0.248788\n",
      "[277]\ttraining's binary_logloss: 0.248775\n",
      "[278]\ttraining's binary_logloss: 0.248763\n",
      "[279]\ttraining's binary_logloss: 0.248751\n",
      "[280]\ttraining's binary_logloss: 0.248739\n",
      "[281]\ttraining's binary_logloss: 0.248727\n",
      "[282]\ttraining's binary_logloss: 0.248715\n",
      "[283]\ttraining's binary_logloss: 0.248703\n",
      "[284]\ttraining's binary_logloss: 0.248691\n",
      "[285]\ttraining's binary_logloss: 0.24868\n",
      "[286]\ttraining's binary_logloss: 0.248668\n",
      "[287]\ttraining's binary_logloss: 0.248657\n",
      "[288]\ttraining's binary_logloss: 0.248645\n",
      "[289]\ttraining's binary_logloss: 0.248634\n",
      "[290]\ttraining's binary_logloss: 0.248622\n",
      "[291]\ttraining's binary_logloss: 0.248611\n",
      "[292]\ttraining's binary_logloss: 0.2486\n",
      "[293]\ttraining's binary_logloss: 0.248589\n",
      "[294]\ttraining's binary_logloss: 0.248578\n",
      "[295]\ttraining's binary_logloss: 0.248567\n",
      "[296]\ttraining's binary_logloss: 0.248555\n",
      "[297]\ttraining's binary_logloss: 0.248545\n",
      "[298]\ttraining's binary_logloss: 0.248534\n",
      "[299]\ttraining's binary_logloss: 0.248524\n",
      "[300]\ttraining's binary_logloss: 0.248513\n",
      "[301]\ttraining's binary_logloss: 0.248503\n",
      "[302]\ttraining's binary_logloss: 0.248492\n",
      "[303]\ttraining's binary_logloss: 0.248482\n",
      "[304]\ttraining's binary_logloss: 0.248472\n",
      "[305]\ttraining's binary_logloss: 0.248461\n",
      "[306]\ttraining's binary_logloss: 0.248451\n",
      "[307]\ttraining's binary_logloss: 0.24844\n",
      "[308]\ttraining's binary_logloss: 0.24843\n",
      "[309]\ttraining's binary_logloss: 0.24842\n",
      "[310]\ttraining's binary_logloss: 0.24841\n",
      "[311]\ttraining's binary_logloss: 0.2484\n",
      "[312]\ttraining's binary_logloss: 0.24839\n",
      "[313]\ttraining's binary_logloss: 0.24838\n",
      "[314]\ttraining's binary_logloss: 0.24837\n",
      "[315]\ttraining's binary_logloss: 0.24836\n",
      "[316]\ttraining's binary_logloss: 0.24835\n",
      "[317]\ttraining's binary_logloss: 0.24834\n",
      "[318]\ttraining's binary_logloss: 0.24833\n",
      "[319]\ttraining's binary_logloss: 0.24832\n",
      "[320]\ttraining's binary_logloss: 0.248311\n",
      "[321]\ttraining's binary_logloss: 0.248301\n",
      "[322]\ttraining's binary_logloss: 0.248291\n",
      "[323]\ttraining's binary_logloss: 0.248282\n",
      "[324]\ttraining's binary_logloss: 0.248272\n",
      "[325]\ttraining's binary_logloss: 0.248263\n",
      "[326]\ttraining's binary_logloss: 0.248254\n",
      "[327]\ttraining's binary_logloss: 0.248245\n",
      "[328]\ttraining's binary_logloss: 0.248235\n",
      "[329]\ttraining's binary_logloss: 0.248226\n",
      "[330]\ttraining's binary_logloss: 0.248217\n",
      "[331]\ttraining's binary_logloss: 0.248207\n",
      "[332]\ttraining's binary_logloss: 0.248198\n",
      "[333]\ttraining's binary_logloss: 0.248189\n",
      "[334]\ttraining's binary_logloss: 0.24818\n",
      "[335]\ttraining's binary_logloss: 0.248171\n",
      "[336]\ttraining's binary_logloss: 0.248162\n",
      "[337]\ttraining's binary_logloss: 0.248153\n",
      "[338]\ttraining's binary_logloss: 0.248143\n",
      "[339]\ttraining's binary_logloss: 0.248134\n",
      "[340]\ttraining's binary_logloss: 0.248125\n",
      "[341]\ttraining's binary_logloss: 0.248116\n",
      "[342]\ttraining's binary_logloss: 0.248108\n",
      "[343]\ttraining's binary_logloss: 0.248099\n",
      "[344]\ttraining's binary_logloss: 0.248091\n",
      "[345]\ttraining's binary_logloss: 0.248082\n",
      "[346]\ttraining's binary_logloss: 0.248074\n",
      "[347]\ttraining's binary_logloss: 0.248065\n",
      "[348]\ttraining's binary_logloss: 0.248056\n",
      "[349]\ttraining's binary_logloss: 0.248048\n",
      "[350]\ttraining's binary_logloss: 0.248039\n",
      "[351]\ttraining's binary_logloss: 0.248031\n",
      "[352]\ttraining's binary_logloss: 0.248023\n",
      "[353]\ttraining's binary_logloss: 0.248014\n",
      "[354]\ttraining's binary_logloss: 0.248006\n",
      "[355]\ttraining's binary_logloss: 0.247998\n",
      "[356]\ttraining's binary_logloss: 0.24799\n",
      "[357]\ttraining's binary_logloss: 0.247982\n",
      "[358]\ttraining's binary_logloss: 0.247974\n",
      "[359]\ttraining's binary_logloss: 0.247965\n",
      "[360]\ttraining's binary_logloss: 0.247957\n",
      "[361]\ttraining's binary_logloss: 0.247949\n",
      "[362]\ttraining's binary_logloss: 0.247941\n",
      "[363]\ttraining's binary_logloss: 0.247934\n",
      "[364]\ttraining's binary_logloss: 0.247926\n",
      "[365]\ttraining's binary_logloss: 0.247918\n",
      "[366]\ttraining's binary_logloss: 0.24791\n",
      "[367]\ttraining's binary_logloss: 0.247902\n",
      "[368]\ttraining's binary_logloss: 0.247894\n",
      "[369]\ttraining's binary_logloss: 0.247886\n",
      "[370]\ttraining's binary_logloss: 0.247879\n",
      "[371]\ttraining's binary_logloss: 0.247871\n",
      "[372]\ttraining's binary_logloss: 0.247863\n",
      "[373]\ttraining's binary_logloss: 0.247855\n",
      "[374]\ttraining's binary_logloss: 0.247848\n",
      "[375]\ttraining's binary_logloss: 0.24784\n",
      "[376]\ttraining's binary_logloss: 0.247832\n",
      "[377]\ttraining's binary_logloss: 0.247825\n",
      "[378]\ttraining's binary_logloss: 0.247818\n",
      "[379]\ttraining's binary_logloss: 0.24781\n",
      "[380]\ttraining's binary_logloss: 0.247802\n",
      "[381]\ttraining's binary_logloss: 0.247795\n",
      "[382]\ttraining's binary_logloss: 0.247787\n",
      "[383]\ttraining's binary_logloss: 0.24778\n",
      "[384]\ttraining's binary_logloss: 0.247772\n",
      "[385]\ttraining's binary_logloss: 0.247765\n",
      "[386]\ttraining's binary_logloss: 0.247758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387]\ttraining's binary_logloss: 0.247751\n",
      "[388]\ttraining's binary_logloss: 0.247744\n",
      "[389]\ttraining's binary_logloss: 0.247737\n",
      "[390]\ttraining's binary_logloss: 0.24773\n",
      "[391]\ttraining's binary_logloss: 0.247723\n",
      "[392]\ttraining's binary_logloss: 0.247716\n",
      "[393]\ttraining's binary_logloss: 0.247709\n",
      "[394]\ttraining's binary_logloss: 0.247702\n",
      "[395]\ttraining's binary_logloss: 0.247694\n",
      "[396]\ttraining's binary_logloss: 0.247687\n",
      "[397]\ttraining's binary_logloss: 0.24768\n",
      "[398]\ttraining's binary_logloss: 0.247672\n",
      "[399]\ttraining's binary_logloss: 0.247665\n",
      "[400]\ttraining's binary_logloss: 0.247658\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.247658\n",
      "[1]\ttraining's binary_logloss: 0.277149\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's binary_logloss: 0.274528\n",
      "[3]\ttraining's binary_logloss: 0.272455\n",
      "[4]\ttraining's binary_logloss: 0.27069\n",
      "[5]\ttraining's binary_logloss: 0.269246\n",
      "[6]\ttraining's binary_logloss: 0.268016\n",
      "[7]\ttraining's binary_logloss: 0.266886\n",
      "[8]\ttraining's binary_logloss: 0.265941\n",
      "[9]\ttraining's binary_logloss: 0.265135\n",
      "[10]\ttraining's binary_logloss: 0.264396\n",
      "[11]\ttraining's binary_logloss: 0.26375\n",
      "[12]\ttraining's binary_logloss: 0.263134\n",
      "[13]\ttraining's binary_logloss: 0.262587\n",
      "[14]\ttraining's binary_logloss: 0.262108\n",
      "[15]\ttraining's binary_logloss: 0.261678\n",
      "[16]\ttraining's binary_logloss: 0.261278\n",
      "[17]\ttraining's binary_logloss: 0.260911\n",
      "[18]\ttraining's binary_logloss: 0.260583\n",
      "[19]\ttraining's binary_logloss: 0.260289\n",
      "[20]\ttraining's binary_logloss: 0.260013\n",
      "[21]\ttraining's binary_logloss: 0.259749\n",
      "[22]\ttraining's binary_logloss: 0.259508\n",
      "[23]\ttraining's binary_logloss: 0.259274\n",
      "[24]\ttraining's binary_logloss: 0.259057\n",
      "[25]\ttraining's binary_logloss: 0.258841\n",
      "[26]\ttraining's binary_logloss: 0.258636\n",
      "[27]\ttraining's binary_logloss: 0.258446\n",
      "[28]\ttraining's binary_logloss: 0.258265\n",
      "[29]\ttraining's binary_logloss: 0.258089\n",
      "[30]\ttraining's binary_logloss: 0.257922\n",
      "[31]\ttraining's binary_logloss: 0.257759\n",
      "[32]\ttraining's binary_logloss: 0.257603\n",
      "[33]\ttraining's binary_logloss: 0.257458\n",
      "[34]\ttraining's binary_logloss: 0.257315\n",
      "[35]\ttraining's binary_logloss: 0.25718\n",
      "[36]\ttraining's binary_logloss: 0.257052\n",
      "[37]\ttraining's binary_logloss: 0.256928\n",
      "[38]\ttraining's binary_logloss: 0.256804\n",
      "[39]\ttraining's binary_logloss: 0.256685\n",
      "[40]\ttraining's binary_logloss: 0.25657\n",
      "[41]\ttraining's binary_logloss: 0.256459\n",
      "[42]\ttraining's binary_logloss: 0.256353\n",
      "[43]\ttraining's binary_logloss: 0.25625\n",
      "[44]\ttraining's binary_logloss: 0.25615\n",
      "[45]\ttraining's binary_logloss: 0.256051\n",
      "[46]\ttraining's binary_logloss: 0.255959\n",
      "[47]\ttraining's binary_logloss: 0.255869\n",
      "[48]\ttraining's binary_logloss: 0.255781\n",
      "[49]\ttraining's binary_logloss: 0.255695\n",
      "[50]\ttraining's binary_logloss: 0.255611\n",
      "[51]\ttraining's binary_logloss: 0.255527\n",
      "[52]\ttraining's binary_logloss: 0.255443\n",
      "[53]\ttraining's binary_logloss: 0.255363\n",
      "[54]\ttraining's binary_logloss: 0.255286\n",
      "[55]\ttraining's binary_logloss: 0.255211\n",
      "[56]\ttraining's binary_logloss: 0.255136\n",
      "[57]\ttraining's binary_logloss: 0.255064\n",
      "[58]\ttraining's binary_logloss: 0.254992\n",
      "[59]\ttraining's binary_logloss: 0.254921\n",
      "[60]\ttraining's binary_logloss: 0.254852\n",
      "[61]\ttraining's binary_logloss: 0.254785\n",
      "[62]\ttraining's binary_logloss: 0.254719\n",
      "[63]\ttraining's binary_logloss: 0.254654\n",
      "[64]\ttraining's binary_logloss: 0.254587\n",
      "[65]\ttraining's binary_logloss: 0.254523\n",
      "[66]\ttraining's binary_logloss: 0.25446\n",
      "[67]\ttraining's binary_logloss: 0.254398\n",
      "[68]\ttraining's binary_logloss: 0.25434\n",
      "[69]\ttraining's binary_logloss: 0.254283\n",
      "[70]\ttraining's binary_logloss: 0.254227\n",
      "[71]\ttraining's binary_logloss: 0.254171\n",
      "[72]\ttraining's binary_logloss: 0.254115\n",
      "[73]\ttraining's binary_logloss: 0.254061\n",
      "[74]\ttraining's binary_logloss: 0.254009\n",
      "[75]\ttraining's binary_logloss: 0.253958\n",
      "[76]\ttraining's binary_logloss: 0.253907\n",
      "[77]\ttraining's binary_logloss: 0.253857\n",
      "[78]\ttraining's binary_logloss: 0.253803\n",
      "[79]\ttraining's binary_logloss: 0.253754\n",
      "[80]\ttraining's binary_logloss: 0.253705\n",
      "[81]\ttraining's binary_logloss: 0.253657\n",
      "[82]\ttraining's binary_logloss: 0.25361\n",
      "[83]\ttraining's binary_logloss: 0.253563\n",
      "[84]\ttraining's binary_logloss: 0.253516\n",
      "[85]\ttraining's binary_logloss: 0.253471\n",
      "[86]\ttraining's binary_logloss: 0.253427\n",
      "[87]\ttraining's binary_logloss: 0.25338\n",
      "[88]\ttraining's binary_logloss: 0.253338\n",
      "[89]\ttraining's binary_logloss: 0.253296\n",
      "[90]\ttraining's binary_logloss: 0.253254\n",
      "[91]\ttraining's binary_logloss: 0.253212\n",
      "[92]\ttraining's binary_logloss: 0.253173\n",
      "[93]\ttraining's binary_logloss: 0.253133\n",
      "[94]\ttraining's binary_logloss: 0.253094\n",
      "[95]\ttraining's binary_logloss: 0.253054\n",
      "[96]\ttraining's binary_logloss: 0.253015\n",
      "[97]\ttraining's binary_logloss: 0.252977\n",
      "[98]\ttraining's binary_logloss: 0.25294\n",
      "[99]\ttraining's binary_logloss: 0.252902\n",
      "[100]\ttraining's binary_logloss: 0.252864\n",
      "[101]\ttraining's binary_logloss: 0.252828\n",
      "[102]\ttraining's binary_logloss: 0.252792\n",
      "[103]\ttraining's binary_logloss: 0.252757\n",
      "[104]\ttraining's binary_logloss: 0.252723\n",
      "[105]\ttraining's binary_logloss: 0.252687\n",
      "[106]\ttraining's binary_logloss: 0.252653\n",
      "[107]\ttraining's binary_logloss: 0.252618\n",
      "[108]\ttraining's binary_logloss: 0.252586\n",
      "[109]\ttraining's binary_logloss: 0.252553\n",
      "[110]\ttraining's binary_logloss: 0.252521\n",
      "[111]\ttraining's binary_logloss: 0.252487\n",
      "[112]\ttraining's binary_logloss: 0.252455\n",
      "[113]\ttraining's binary_logloss: 0.252423\n",
      "[114]\ttraining's binary_logloss: 0.252391\n",
      "[115]\ttraining's binary_logloss: 0.252359\n",
      "[116]\ttraining's binary_logloss: 0.252328\n",
      "[117]\ttraining's binary_logloss: 0.252298\n",
      "[118]\ttraining's binary_logloss: 0.252267\n",
      "[119]\ttraining's binary_logloss: 0.252236\n",
      "[120]\ttraining's binary_logloss: 0.252206\n",
      "[121]\ttraining's binary_logloss: 0.252176\n",
      "[122]\ttraining's binary_logloss: 0.252147\n",
      "[123]\ttraining's binary_logloss: 0.252118\n",
      "[124]\ttraining's binary_logloss: 0.252089\n",
      "[125]\ttraining's binary_logloss: 0.252061\n",
      "[126]\ttraining's binary_logloss: 0.252033\n",
      "[127]\ttraining's binary_logloss: 0.252005\n",
      "[128]\ttraining's binary_logloss: 0.251977\n",
      "[129]\ttraining's binary_logloss: 0.251949\n",
      "[130]\ttraining's binary_logloss: 0.251922\n",
      "[131]\ttraining's binary_logloss: 0.251894\n",
      "[132]\ttraining's binary_logloss: 0.251866\n",
      "[133]\ttraining's binary_logloss: 0.251839\n",
      "[134]\ttraining's binary_logloss: 0.251812\n",
      "[135]\ttraining's binary_logloss: 0.251785\n",
      "[136]\ttraining's binary_logloss: 0.251759\n",
      "[137]\ttraining's binary_logloss: 0.251733\n",
      "[138]\ttraining's binary_logloss: 0.251707\n",
      "[139]\ttraining's binary_logloss: 0.251679\n",
      "[140]\ttraining's binary_logloss: 0.251654\n",
      "[141]\ttraining's binary_logloss: 0.251629\n",
      "[142]\ttraining's binary_logloss: 0.251604\n",
      "[143]\ttraining's binary_logloss: 0.25158\n",
      "[144]\ttraining's binary_logloss: 0.251555\n",
      "[145]\ttraining's binary_logloss: 0.25153\n",
      "[146]\ttraining's binary_logloss: 0.251506\n",
      "[147]\ttraining's binary_logloss: 0.251482\n",
      "[148]\ttraining's binary_logloss: 0.251458\n",
      "[149]\ttraining's binary_logloss: 0.251434\n",
      "[150]\ttraining's binary_logloss: 0.25141\n",
      "[151]\ttraining's binary_logloss: 0.251387\n",
      "[152]\ttraining's binary_logloss: 0.251364\n",
      "[153]\ttraining's binary_logloss: 0.251341\n",
      "[154]\ttraining's binary_logloss: 0.251318\n",
      "[155]\ttraining's binary_logloss: 0.251296\n",
      "[156]\ttraining's binary_logloss: 0.251273\n",
      "[157]\ttraining's binary_logloss: 0.25125\n",
      "[158]\ttraining's binary_logloss: 0.251228\n",
      "[159]\ttraining's binary_logloss: 0.251206\n",
      "[160]\ttraining's binary_logloss: 0.251184\n",
      "[161]\ttraining's binary_logloss: 0.251162\n",
      "[162]\ttraining's binary_logloss: 0.251141\n",
      "[163]\ttraining's binary_logloss: 0.251119\n",
      "[164]\ttraining's binary_logloss: 0.251099\n",
      "[165]\ttraining's binary_logloss: 0.251078\n",
      "[166]\ttraining's binary_logloss: 0.251056\n",
      "[167]\ttraining's binary_logloss: 0.251035\n",
      "[168]\ttraining's binary_logloss: 0.251015\n",
      "[169]\ttraining's binary_logloss: 0.250995\n",
      "[170]\ttraining's binary_logloss: 0.250975\n",
      "[171]\ttraining's binary_logloss: 0.250955\n",
      "[172]\ttraining's binary_logloss: 0.250935\n",
      "[173]\ttraining's binary_logloss: 0.250915\n",
      "[174]\ttraining's binary_logloss: 0.250895\n",
      "[175]\ttraining's binary_logloss: 0.250875\n",
      "[176]\ttraining's binary_logloss: 0.250855\n",
      "[177]\ttraining's binary_logloss: 0.250836\n",
      "[178]\ttraining's binary_logloss: 0.250817\n",
      "[179]\ttraining's binary_logloss: 0.250797\n",
      "[180]\ttraining's binary_logloss: 0.250779\n",
      "[181]\ttraining's binary_logloss: 0.25076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182]\ttraining's binary_logloss: 0.250742\n",
      "[183]\ttraining's binary_logloss: 0.250723\n",
      "[184]\ttraining's binary_logloss: 0.250704\n",
      "[185]\ttraining's binary_logloss: 0.250685\n",
      "[186]\ttraining's binary_logloss: 0.250667\n",
      "[187]\ttraining's binary_logloss: 0.250649\n",
      "[188]\ttraining's binary_logloss: 0.250631\n",
      "[189]\ttraining's binary_logloss: 0.250614\n",
      "[190]\ttraining's binary_logloss: 0.250596\n",
      "[191]\ttraining's binary_logloss: 0.250578\n",
      "[192]\ttraining's binary_logloss: 0.250561\n",
      "[193]\ttraining's binary_logloss: 0.250544\n",
      "[194]\ttraining's binary_logloss: 0.250527\n",
      "[195]\ttraining's binary_logloss: 0.250509\n",
      "[196]\ttraining's binary_logloss: 0.250492\n",
      "[197]\ttraining's binary_logloss: 0.250474\n",
      "[198]\ttraining's binary_logloss: 0.250457\n",
      "[199]\ttraining's binary_logloss: 0.25044\n",
      "[200]\ttraining's binary_logloss: 0.250423\n",
      "[201]\ttraining's binary_logloss: 0.250407\n",
      "[202]\ttraining's binary_logloss: 0.250391\n",
      "[203]\ttraining's binary_logloss: 0.250375\n",
      "[204]\ttraining's binary_logloss: 0.250358\n",
      "[205]\ttraining's binary_logloss: 0.250342\n",
      "[206]\ttraining's binary_logloss: 0.250326\n",
      "[207]\ttraining's binary_logloss: 0.25031\n",
      "[208]\ttraining's binary_logloss: 0.250294\n",
      "[209]\ttraining's binary_logloss: 0.250278\n",
      "[210]\ttraining's binary_logloss: 0.250263\n",
      "[211]\ttraining's binary_logloss: 0.250247\n",
      "[212]\ttraining's binary_logloss: 0.250232\n",
      "[213]\ttraining's binary_logloss: 0.250216\n",
      "[214]\ttraining's binary_logloss: 0.250201\n",
      "[215]\ttraining's binary_logloss: 0.250186\n",
      "[216]\ttraining's binary_logloss: 0.250172\n",
      "[217]\ttraining's binary_logloss: 0.250157\n",
      "[218]\ttraining's binary_logloss: 0.250143\n",
      "[219]\ttraining's binary_logloss: 0.250128\n",
      "[220]\ttraining's binary_logloss: 0.250114\n",
      "[221]\ttraining's binary_logloss: 0.2501\n",
      "[222]\ttraining's binary_logloss: 0.250085\n",
      "[223]\ttraining's binary_logloss: 0.250071\n",
      "[224]\ttraining's binary_logloss: 0.250057\n",
      "[225]\ttraining's binary_logloss: 0.250044\n",
      "[226]\ttraining's binary_logloss: 0.25003\n",
      "[227]\ttraining's binary_logloss: 0.250016\n",
      "[228]\ttraining's binary_logloss: 0.250003\n",
      "[229]\ttraining's binary_logloss: 0.249989\n",
      "[230]\ttraining's binary_logloss: 0.249976\n",
      "[231]\ttraining's binary_logloss: 0.249962\n",
      "[232]\ttraining's binary_logloss: 0.249949\n",
      "[233]\ttraining's binary_logloss: 0.249936\n",
      "[234]\ttraining's binary_logloss: 0.249922\n",
      "[235]\ttraining's binary_logloss: 0.249909\n",
      "[236]\ttraining's binary_logloss: 0.249896\n",
      "[237]\ttraining's binary_logloss: 0.249882\n",
      "[238]\ttraining's binary_logloss: 0.249869\n",
      "[239]\ttraining's binary_logloss: 0.249855\n",
      "[240]\ttraining's binary_logloss: 0.249842\n",
      "[241]\ttraining's binary_logloss: 0.24983\n",
      "[242]\ttraining's binary_logloss: 0.249817\n",
      "[243]\ttraining's binary_logloss: 0.249804\n",
      "[244]\ttraining's binary_logloss: 0.249791\n",
      "[245]\ttraining's binary_logloss: 0.249779\n",
      "[246]\ttraining's binary_logloss: 0.249766\n",
      "[247]\ttraining's binary_logloss: 0.249754\n",
      "[248]\ttraining's binary_logloss: 0.249741\n",
      "[249]\ttraining's binary_logloss: 0.249729\n",
      "[250]\ttraining's binary_logloss: 0.249717\n",
      "[251]\ttraining's binary_logloss: 0.249705\n",
      "[252]\ttraining's binary_logloss: 0.249693\n",
      "[253]\ttraining's binary_logloss: 0.249681\n",
      "[254]\ttraining's binary_logloss: 0.249669\n",
      "[255]\ttraining's binary_logloss: 0.249657\n",
      "[256]\ttraining's binary_logloss: 0.249646\n",
      "[257]\ttraining's binary_logloss: 0.249634\n",
      "[258]\ttraining's binary_logloss: 0.249622\n",
      "[259]\ttraining's binary_logloss: 0.249611\n",
      "[260]\ttraining's binary_logloss: 0.249599\n",
      "[261]\ttraining's binary_logloss: 0.249588\n",
      "[262]\ttraining's binary_logloss: 0.249577\n",
      "[263]\ttraining's binary_logloss: 0.249565\n",
      "[264]\ttraining's binary_logloss: 0.249554\n",
      "[265]\ttraining's binary_logloss: 0.249543\n",
      "[266]\ttraining's binary_logloss: 0.249532\n",
      "[267]\ttraining's binary_logloss: 0.249521\n",
      "[268]\ttraining's binary_logloss: 0.24951\n",
      "[269]\ttraining's binary_logloss: 0.249499\n",
      "[270]\ttraining's binary_logloss: 0.249488\n",
      "[271]\ttraining's binary_logloss: 0.249477\n",
      "[272]\ttraining's binary_logloss: 0.249466\n",
      "[273]\ttraining's binary_logloss: 0.249456\n",
      "[274]\ttraining's binary_logloss: 0.249445\n",
      "[275]\ttraining's binary_logloss: 0.249434\n",
      "[276]\ttraining's binary_logloss: 0.249423\n",
      "[277]\ttraining's binary_logloss: 0.249413\n",
      "[278]\ttraining's binary_logloss: 0.249402\n",
      "[279]\ttraining's binary_logloss: 0.249392\n",
      "[280]\ttraining's binary_logloss: 0.249381\n",
      "[281]\ttraining's binary_logloss: 0.249371\n",
      "[282]\ttraining's binary_logloss: 0.249361\n",
      "[283]\ttraining's binary_logloss: 0.24935\n",
      "[284]\ttraining's binary_logloss: 0.24934\n",
      "[285]\ttraining's binary_logloss: 0.24933\n",
      "[286]\ttraining's binary_logloss: 0.24932\n",
      "[287]\ttraining's binary_logloss: 0.249309\n",
      "[288]\ttraining's binary_logloss: 0.249299\n",
      "[289]\ttraining's binary_logloss: 0.24929\n",
      "[290]\ttraining's binary_logloss: 0.24928\n",
      "[291]\ttraining's binary_logloss: 0.24927\n",
      "[292]\ttraining's binary_logloss: 0.24926\n",
      "[293]\ttraining's binary_logloss: 0.249249\n",
      "[294]\ttraining's binary_logloss: 0.249239\n",
      "[295]\ttraining's binary_logloss: 0.249229\n",
      "[296]\ttraining's binary_logloss: 0.24922\n",
      "[297]\ttraining's binary_logloss: 0.24921\n",
      "[298]\ttraining's binary_logloss: 0.2492\n",
      "[299]\ttraining's binary_logloss: 0.249191\n",
      "[300]\ttraining's binary_logloss: 0.249181\n",
      "[301]\ttraining's binary_logloss: 0.249172\n",
      "[302]\ttraining's binary_logloss: 0.249162\n",
      "[303]\ttraining's binary_logloss: 0.249153\n",
      "[304]\ttraining's binary_logloss: 0.249143\n",
      "[305]\ttraining's binary_logloss: 0.249134\n",
      "[306]\ttraining's binary_logloss: 0.249123\n",
      "[307]\ttraining's binary_logloss: 0.249114\n",
      "[308]\ttraining's binary_logloss: 0.249105\n",
      "[309]\ttraining's binary_logloss: 0.249096\n",
      "[310]\ttraining's binary_logloss: 0.249086\n",
      "[311]\ttraining's binary_logloss: 0.249077\n",
      "[312]\ttraining's binary_logloss: 0.249068\n",
      "[313]\ttraining's binary_logloss: 0.249059\n",
      "[314]\ttraining's binary_logloss: 0.24905\n",
      "[315]\ttraining's binary_logloss: 0.249041\n",
      "[316]\ttraining's binary_logloss: 0.249032\n",
      "[317]\ttraining's binary_logloss: 0.249023\n",
      "[318]\ttraining's binary_logloss: 0.249014\n",
      "[319]\ttraining's binary_logloss: 0.249006\n",
      "[320]\ttraining's binary_logloss: 0.248997\n",
      "[321]\ttraining's binary_logloss: 0.248988\n",
      "[322]\ttraining's binary_logloss: 0.24898\n",
      "[323]\ttraining's binary_logloss: 0.24897\n",
      "[324]\ttraining's binary_logloss: 0.248961\n",
      "[325]\ttraining's binary_logloss: 0.248953\n",
      "[326]\ttraining's binary_logloss: 0.248944\n",
      "[327]\ttraining's binary_logloss: 0.248935\n",
      "[328]\ttraining's binary_logloss: 0.248927\n",
      "[329]\ttraining's binary_logloss: 0.248919\n",
      "[330]\ttraining's binary_logloss: 0.24891\n",
      "[331]\ttraining's binary_logloss: 0.248902\n",
      "[332]\ttraining's binary_logloss: 0.248893\n",
      "[333]\ttraining's binary_logloss: 0.248884\n",
      "[334]\ttraining's binary_logloss: 0.248876\n",
      "[335]\ttraining's binary_logloss: 0.248868\n",
      "[336]\ttraining's binary_logloss: 0.248859\n",
      "[337]\ttraining's binary_logloss: 0.248851\n",
      "[338]\ttraining's binary_logloss: 0.248842\n",
      "[339]\ttraining's binary_logloss: 0.248834\n",
      "[340]\ttraining's binary_logloss: 0.248826\n",
      "[341]\ttraining's binary_logloss: 0.248818\n",
      "[342]\ttraining's binary_logloss: 0.24881\n",
      "[343]\ttraining's binary_logloss: 0.248802\n",
      "[344]\ttraining's binary_logloss: 0.248794\n",
      "[345]\ttraining's binary_logloss: 0.248786\n",
      "[346]\ttraining's binary_logloss: 0.248778\n",
      "[347]\ttraining's binary_logloss: 0.24877\n",
      "[348]\ttraining's binary_logloss: 0.248762\n",
      "[349]\ttraining's binary_logloss: 0.248754\n",
      "[350]\ttraining's binary_logloss: 0.248746\n",
      "[351]\ttraining's binary_logloss: 0.248738\n",
      "[352]\ttraining's binary_logloss: 0.24873\n",
      "[353]\ttraining's binary_logloss: 0.248723\n",
      "[354]\ttraining's binary_logloss: 0.248715\n",
      "[355]\ttraining's binary_logloss: 0.248707\n",
      "[356]\ttraining's binary_logloss: 0.248699\n",
      "[357]\ttraining's binary_logloss: 0.248691\n",
      "[358]\ttraining's binary_logloss: 0.248684\n",
      "[359]\ttraining's binary_logloss: 0.248676\n",
      "[360]\ttraining's binary_logloss: 0.248668\n",
      "[361]\ttraining's binary_logloss: 0.24866\n",
      "[362]\ttraining's binary_logloss: 0.248652\n",
      "[363]\ttraining's binary_logloss: 0.248644\n",
      "[364]\ttraining's binary_logloss: 0.248637\n",
      "[365]\ttraining's binary_logloss: 0.248629\n",
      "[366]\ttraining's binary_logloss: 0.248622\n",
      "[367]\ttraining's binary_logloss: 0.248615\n",
      "[368]\ttraining's binary_logloss: 0.248608\n",
      "[369]\ttraining's binary_logloss: 0.2486\n",
      "[370]\ttraining's binary_logloss: 0.248593\n",
      "[371]\ttraining's binary_logloss: 0.248586\n",
      "[372]\ttraining's binary_logloss: 0.248578\n",
      "[373]\ttraining's binary_logloss: 0.248571\n",
      "[374]\ttraining's binary_logloss: 0.248564\n",
      "[375]\ttraining's binary_logloss: 0.248557\n",
      "[376]\ttraining's binary_logloss: 0.24855\n",
      "[377]\ttraining's binary_logloss: 0.248543\n",
      "[378]\ttraining's binary_logloss: 0.248536\n",
      "[379]\ttraining's binary_logloss: 0.248529\n",
      "[380]\ttraining's binary_logloss: 0.248522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[381]\ttraining's binary_logloss: 0.248515\n",
      "[382]\ttraining's binary_logloss: 0.248508\n",
      "[383]\ttraining's binary_logloss: 0.248501\n",
      "[384]\ttraining's binary_logloss: 0.248494\n",
      "[385]\ttraining's binary_logloss: 0.248487\n",
      "[386]\ttraining's binary_logloss: 0.24848\n",
      "[387]\ttraining's binary_logloss: 0.248474\n",
      "[388]\ttraining's binary_logloss: 0.248467\n",
      "[389]\ttraining's binary_logloss: 0.24846\n",
      "[390]\ttraining's binary_logloss: 0.248453\n",
      "[391]\ttraining's binary_logloss: 0.248446\n",
      "[392]\ttraining's binary_logloss: 0.24844\n",
      "[393]\ttraining's binary_logloss: 0.248433\n",
      "[394]\ttraining's binary_logloss: 0.248426\n",
      "[395]\ttraining's binary_logloss: 0.248419\n",
      "[396]\ttraining's binary_logloss: 0.248413\n",
      "[397]\ttraining's binary_logloss: 0.248406\n",
      "[398]\ttraining's binary_logloss: 0.2484\n",
      "[399]\ttraining's binary_logloss: 0.248393\n",
      "[400]\ttraining's binary_logloss: 0.248387\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.248387\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "evals1 = [(kg1m_train_f, kg1_train_t)]\n",
    "evals2 = [(kg2m_train_f, kg2_train_t)]\n",
    "evals3 = [(kg3m_train_f, kg3_train_t)]\n",
    "\n",
    "lgbm_wrapper1 = LGBMClassifier(random_state=5, n_estimators=400, max_depth=1)\n",
    "lgbm_wrapper1.fit(kg1m_train_f, kg1_train_t, early_stopping_rounds=100, eval_set=evals1, eval_metric='logloss', verbose=True)\n",
    "lgbm_wrapper1_pred = lgbm_wrapper1.predict(kg1m_test_f)\n",
    "\n",
    "lgbm_wrapper2 = LGBMClassifier(random_state=5, n_estimators=400, max_depth=1)\n",
    "lgbm_wrapper2.fit(kg2m_train_f, kg2_train_t, early_stopping_rounds=100, eval_set=evals2, eval_metric='logloss', verbose=True)\n",
    "lgbm_wrapper2_pred = lgbm_wrapper2.predict(kg2m_test_f)\n",
    "\n",
    "lgbm_wrapper3 = LGBMClassifier(random_state=5, n_estimators=400, max_depth=1)\n",
    "lgbm_wrapper3.fit(kg3m_train_f, kg3_train_t, early_stopping_rounds=100, eval_set=evals3, eval_metric='logloss', verbose=True)\n",
    "lgbm_wrapper3_pred = lgbm_wrapper3.predict(kg3m_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(lgbm_wrapper1.predict_proba(kg1m_test_f))\n",
    "b=pd.DataFrame(lgbm_wrapper2.predict_proba(kg2m_test_f))\n",
    "c=pd.DataFrame(lgbm_wrapper3.predict_proba(kg3m_test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.945095</td>\n",
       "      <td>0.054905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884880</td>\n",
       "      <td>0.115120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.975376</td>\n",
       "      <td>0.024624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.963474</td>\n",
       "      <td>0.036526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.866161</td>\n",
       "      <td>0.133839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>0.962701</td>\n",
       "      <td>0.037299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>0.924802</td>\n",
       "      <td>0.075198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>0.950408</td>\n",
       "      <td>0.049592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>0.938231</td>\n",
       "      <td>0.061769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>0.848986</td>\n",
       "      <td>0.151014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0      0.945095  0.054905\n",
       "1      0.884880  0.115120\n",
       "2      0.975376  0.024624\n",
       "3      0.963474  0.036526\n",
       "4      0.866161  0.133839\n",
       "...         ...       ...\n",
       "48739  0.962701  0.037299\n",
       "48740  0.924802  0.075198\n",
       "48741  0.950408  0.049592\n",
       "48742  0.938231  0.061769\n",
       "48743  0.848986  0.151014\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48744.000000</td>\n",
       "      <td>48744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.919058</td>\n",
       "      <td>0.080942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.067185</td>\n",
       "      <td>0.067185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.232451</td>\n",
       "      <td>0.005008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.896415</td>\n",
       "      <td>0.035793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.939509</td>\n",
       "      <td>0.060491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.964207</td>\n",
       "      <td>0.103585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.994992</td>\n",
       "      <td>0.767549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "count  48744.000000  48744.000000\n",
       "mean       0.919058      0.080942\n",
       "std        0.067185      0.067185\n",
       "min        0.232451      0.005008\n",
       "25%        0.896415      0.035793\n",
       "50%        0.939509      0.060491\n",
       "75%        0.964207      0.103585\n",
       "max        0.994992      0.767549"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48744.000000</td>\n",
       "      <td>48744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.918851</td>\n",
       "      <td>0.081149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.068653</td>\n",
       "      <td>0.068653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.227528</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.895922</td>\n",
       "      <td>0.035006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.939871</td>\n",
       "      <td>0.060129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.964994</td>\n",
       "      <td>0.104078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.772472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "count  48744.000000  48744.000000\n",
       "mean       0.918851      0.081149\n",
       "std        0.068653      0.068653\n",
       "min        0.227528      0.004137\n",
       "25%        0.895922      0.035006\n",
       "50%        0.939871      0.060129\n",
       "75%        0.964994      0.104078\n",
       "max        0.995863      0.772472"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48744.000000</td>\n",
       "      <td>48744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.919435</td>\n",
       "      <td>0.080565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.067216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.470267</td>\n",
       "      <td>0.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.893949</td>\n",
       "      <td>0.032481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.941203</td>\n",
       "      <td>0.058797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.967519</td>\n",
       "      <td>0.106051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.994725</td>\n",
       "      <td>0.529733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "count  48744.000000  48744.000000\n",
       "mean       0.919435      0.080565\n",
       "std        0.067216      0.067216\n",
       "min        0.470267      0.005275\n",
       "25%        0.893949      0.032481\n",
       "50%        0.941203      0.058797\n",
       "75%        0.967519      0.106051\n",
       "max        0.994725      0.529733"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a[0].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a[1].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['TARGET']=a[1].apply(lambda x : 1 if x>=0.1 else 0)\n",
    "b['TARGET']=b[1].apply(lambda x : 1 if x>=0.1 else 0)\n",
    "c['TARGET']=c[1].apply(lambda x : 1 if x>=0.1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a['TARGET']\n",
    "b=b['TARGET']\n",
    "c=c['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "48739    0\n",
       "48740    0\n",
       "48741    0\n",
       "48742    0\n",
       "48743    1\n",
       "Name: TARGET, Length: 48744, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=pd.DataFrame(kg1_test_f[\"SK_ID_CURR\"])\n",
    "\n",
    "ID['TARGET']=a\n",
    "ID.to_csv(r\"C:\\Users\\ASUS VivoBook\\pred_kg1m_change.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=pd.DataFrame(kg2_test_f[\"SK_ID_CURR\"])\n",
    "\n",
    "ID['TARGET']=b\n",
    "ID.to_csv(r\"C:\\Users\\ASUS VivoBook\\pred_kg2m_change.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=pd.DataFrame(kg3_test_f[\"SK_ID_CURR\"])\n",
    "\n",
    "ID['TARGET']=c\n",
    "ID.to_csv(r\"C:\\Users\\ASUS VivoBook\\pred_kg3m_change.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=pd.DataFrame(kg1_test_f[\"SK_ID_CURR\"])\n",
    "\n",
    "ID['TARGET']=lgbm_wrapper1_pred\n",
    "ID.to_csv(r\"C:\\Users\\ASUS VivoBook\\pred_kg1m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=pd.DataFrame(kg2_test_f[\"SK_ID_CURR\"])\n",
    "\n",
    "ID['TARGET']=lgbm_wrapper2_pred\n",
    "ID.to_csv(r\"C:\\Users\\ASUS VivoBook\\pred_kg2m.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID=pd.DataFrame(kg3_test_f[\"SK_ID_CURR\"])\n",
    "\n",
    "ID['TARGET']=lgbm_wrapper3_pred\n",
    "ID.to_csv(r\"C:\\Users\\ASUS VivoBook\\pred_kg3m.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
